{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nat_rng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/nat_rng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/nat_rng/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/nat_rng/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from datetime import datetime\n",
    "from urllib.parse import unquote\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "WIKIDATA_API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "WIKIPEDIA_API_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"uni_coursework/2.0; nat.1.roongjirarat@kcl.ac.uk\"}\n",
    "\n",
    "PARAMS_QUERY_SEARCH = {\n",
    "    \"action\":\"query\",\n",
    "    \"format\":\"json\",\n",
    "    \"formatversion\":\"latest\",\n",
    "    \"list\":\"search\",\n",
    "    \"srsearch\": \"haswbstatement:P166=Q185667\",\n",
    "    \"srlimit\":\"max\"\n",
    "}\n",
    "\n",
    "PARAMS_GETCONTENT = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",\n",
    "    \"prop\": \"extracts\",\n",
    "    \"exlimit\": \"max\"\n",
    "}\n",
    "\n",
    "PARAMS_WBGETENTITIES_LABELS = {\n",
    "    \"action\": \"wbgetentities\",\n",
    "    \"format\": \"json\",\n",
    "    \"ids\": \"\",\n",
    "    \"sites\": \"\",\n",
    "    \"props\": \"labels\",\n",
    "    \"languages\": \"en\",\n",
    "    \"sitefilter\": \"enwiki\",\n",
    "    \"utf8\": 1,\n",
    "    \"ascii\": 1,\n",
    "    \"formatversion\": \"latest\"\n",
    "}\n",
    "\n",
    "PARAMS_WBGETENTITIES_SITES = {\n",
    "    \"action\": \"wbgetentities\",\n",
    "    \"format\": \"json\",\n",
    "    \"ids\": \"\",\n",
    "    \"sites\": \"\",\n",
    "    \"props\": \"sitelinks/urls\",\n",
    "    \"languages\": \"en\",\n",
    "    \"sitefilter\": \"enwiki\",\n",
    "    \"utf8\": 1,\n",
    "    \"ascii\": 1,\n",
    "    \"formatversion\": \"latest\"\n",
    "}\n",
    "\n",
    "PARAMS_WBGETENTITIES_CLAIMS = {\n",
    "    \"action\": \"wbgetentities\",\n",
    "    \"format\": \"json\",\n",
    "    \"ids\": \"\",\n",
    "    \"props\": \"claims\",\n",
    "    \"languages\": \"en\",\n",
    "    \"sitefilter\": \"\",\n",
    "    \"formatversion\": \"latest\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q80', 'Q3572699', 'Q92894', 'Q17457', 'Q92612', 'Q92638', 'Q92743', 'Q92824', 'Q181529', 'Q204815', 'Q578036', 'Q92794', 'Q92739', 'Q49823', 'Q92602', 'Q3571662', 'Q92626', 'Q92758', 'Q16080922', 'Q62870', 'Q8556', 'Q92604', 'Q357965', 'Q11609', 'Q92609', 'Q439245', 'Q92670', 'Q92819', 'Q92851', 'Q92613', 'Q62874', 'Q92854', 'Q92628', 'Q7143512', 'Q62861', 'Q320624', 'Q45575', 'Q1107006', 'Q92614', 'Q62888', 'Q93080', 'Q476466', 'Q92820', 'Q92649', 'Q62898', 'Q92641', 'Q92742', 'Q93154', 'Q62843', 'Q92643', 'Q92823', 'Q462089', 'Q62866', 'Q92629', 'Q92618', 'Q92822', 'Q92596', 'Q92746', 'Q918650', 'Q62857', 'Q92619', 'Q92821', 'Q62877', 'Q92782', 'Q92632', 'Q93161', 'Q92744', 'Q92606', 'Q92781', 'Q9602', 'Q92625', 'Q62894', 'Q92644', 'Q92745', 'Q92828']\n"
     ]
    }
   ],
   "source": [
    "def get_turing_award_recipients():\n",
    "    acm_award_entities = []\n",
    "    search_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_QUERY_SEARCH)\n",
    "    data = search_response.json()\n",
    "    for result in data['query']['search']:\n",
    "        acm_award_entities.append(result['title'])\n",
    "    return acm_award_entities\n",
    "\n",
    "print(get_turing_award_recipients())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_content(entity_id):\n",
    "    PARAMS_WBGETENTITIES_SITES[\"ids\"] = entity_id\n",
    "    wbgetentities_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_WBGETENTITIES_SITES)\n",
    "    wbgetentities_data = wbgetentities_response.json()\n",
    "    recipient_name = wbgetentities_data[\"entities\"][entity_id][\"sitelinks\"][\"enwiki\"][\"url\"].split(\"https://en.wikipedia.org/wiki/\")[1]\n",
    "\n",
    "    PARAMS_GETCONTENT[\"titles\"] = unquote(recipient_name)\n",
    "    extracts_response = requests.get(WIKIPEDIA_API_ENDPOINT, headers=HEADERS, params=PARAMS_GETCONTENT)\n",
    "    extracts_data = extracts_response.json()\n",
    "    html_content = next(iter(extracts_data[\"query\"][\"pages\"].values()))[\"extract\"]\n",
    "    content = BeautifulSoup(html_content, 'html.parser')\n",
    "    if content.find(\"p\", {\"class\":\"mw-empty-elt\"}):\n",
    "        content.find(\"p\", {\"class\":\"mw-empty-elt\"}).decompose()\n",
    "    return str(content)\n",
    "\n",
    "print(get_wikipedia_content(\"Q7143512\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_data_dict = {\"gender\": \"P21\", \"birth_date\": \"P569\", \"birth_city\": \"P19\", \n",
    "                  \"birth_country\": \"P17\", \"employer\": \"P108\", \"educated_at\": \"P69\"}\n",
    "\n",
    "def get_wikidata_claims(entity_id):\n",
    "    PARAMS_WBGETENTITIES_CLAIMS[\"ids\"] = entity_id\n",
    "    wbgetentities_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_WBGETENTITIES_CLAIMS)\n",
    "    wbgetentities_data = wbgetentities_response.json()\n",
    "    claims = next(iter(wbgetentities_data[\"entities\"].values()))[\"claims\"]\n",
    "    return claims\n",
    "\n",
    "def get_wikidata_label(entity_query):\n",
    "    PARAMS_WBGETENTITIES_LABELS[\"ids\"] = entity_query\n",
    "    request_ids = set(entity_query.split(\"|\"))\n",
    "    request_labels = dict()\n",
    "    wbgetentities_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_WBGETENTITIES_LABELS)\n",
    "    wbgetentities_data = wbgetentities_response.json()\n",
    "    for request_id in request_ids:\n",
    "        labels = wbgetentities_data[\"entities\"][request_id][\"labels\"]\n",
    "        request_labels[request_id] = labels[\"en\"][\"value\"]\n",
    "    return request_labels\n",
    "\n",
    "def check_key_exists(dict, key):\n",
    "    if key in dict.keys():\n",
    "        entity_ids = [dict[key][i][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"] for i in range(len(dict[key]))]\n",
    "        return entity_ids\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def call_wikidata_api(entity_id):\n",
    "    claims = get_wikidata_claims(entity_id)\n",
    "    request_entityids = {\"name_id\": [entity_id], \"gender_id\": check_key_exists(claims, wiki_data_dict[\"gender\"]),\n",
    "                       \"birth_city_id\" : check_key_exists(claims, wiki_data_dict[\"birth_city\"]),\n",
    "                       \"employers_ids\": check_key_exists(claims, wiki_data_dict[\"employer\"]),\n",
    "                       \"educated_at_ids\": check_key_exists(claims, wiki_data_dict[\"educated_at\"])}\n",
    "    \n",
    "    \n",
    "    entity_query = \"|\".join([\"|\".join(values) for values in request_entityids.values() if values != None])\n",
    "    request_labels = get_wikidata_label(entity_query)\n",
    "    \n",
    "    try:\n",
    "        name = request_labels[request_entityids[\"name_id\"][0]].split(\" (\")[0]\n",
    "    except TypeError:\n",
    "        name = None\n",
    "    try:\n",
    "        intro = get_wikipedia_content(entity_id).split(\"<h2>\")[0]\n",
    "    except TypeError:\n",
    "        intro = None   \n",
    "    try: \n",
    "        gender = request_labels[request_entityids[\"gender_id\"][0]]\n",
    "    except TypeError:\n",
    "        gender = None\n",
    "    try:\n",
    "        birth_date = datetime.strptime(claims[wiki_data_dict[\"birth_date\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"time\"], \"+%Y-%m-%dT%XZ\").strftime(\"%d %B %Y\")\n",
    "    except ValueError:\n",
    "        birth_date = datetime.strptime(claims[wiki_data_dict[\"birth_date\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"time\"], \"+%Y-00-00T%XZ\").strftime(\"%Y\")\n",
    "    except TypeError:\n",
    "        birth_date = None\n",
    "    try:\n",
    "        birth_place = request_labels[request_entityids[\"birth_city_id\"][0]] \n",
    "    except TypeError:\n",
    "        birth_place = None\n",
    "    try:\n",
    "        employer_list = []\n",
    "        for key in request_entityids[\"employers_ids\"]:\n",
    "            employer = request_labels[key]\n",
    "            employer_list.append(employer)\n",
    "        employer = employer_list\n",
    "    except TypeError:\n",
    "        employer = None\n",
    "    try:\n",
    "        education_list = []\n",
    "        for key in request_entityids[\"educated_at_ids\"]:\n",
    "            education = request_labels[key]\n",
    "            education_list.append(education)\n",
    "        education = education_list\n",
    "    except TypeError:\n",
    "        education = None\n",
    "    return name, intro, gender, birth_date, birth_place, employer, education\n",
    "\n",
    "def multi_thread_api_call(entity_ids, workers=10):\n",
    "    results = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "        api_calls = {executor.submit(call_wikidata_api, entity_id): entity_id for entity_id in entity_ids}\n",
    "        while api_calls:\n",
    "            retry_api_calls = {}\n",
    "            done, pending = wait(api_calls, return_when=FIRST_COMPLETED)\n",
    "            for api_call in done:\n",
    "                if api_call.exception():\n",
    "                    entity_id = api_calls[api_call]\n",
    "                    retry_api_calls[executor.submit(call_wikidata_api, entity_id)] = entity_id\n",
    "                else:\n",
    "                    results.append(api_call.result())\n",
    "            for api_call in pending:\n",
    "                entity_id = api_calls[api_call]\n",
    "                retry_api_calls[api_call] = entity_id\n",
    "            api_calls = retry_api_calls    \n",
    "    return results\n",
    "\n",
    "def get_award_winners_data(results, award_winners_dict):\n",
    "    for result in results:\n",
    "        name, intro, gender, birth_date, birth_place, employer, education = result\n",
    "        award_winners_dict[\"name\"].append(name)\n",
    "        award_winners_dict[\"intro\"].append(intro)\n",
    "        award_winners_dict[\"gender\"].append(gender)\n",
    "        award_winners_dict[\"birth_date\"].append(birth_date)\n",
    "        award_winners_dict[\"birth_place\"].append(birth_place)\n",
    "        award_winners_dict[\"employer\"].append(employer)\n",
    "        award_winners_dict[\"educated_at\"].append(education)\n",
    "    return award_winners_dict\n",
    "\n",
    "award_winners_dict = {\"name\": [], \"intro\": [], \"gender\": [], \"birth_date\": [], \n",
    "                 \"birth_place\": [], \"employer\": [], \"educated_at\": []} \n",
    "acm_award_winners = get_turing_award_recipients()\n",
    "api_calls = multi_thread_api_call(acm_award_winners)\n",
    " \n",
    "award_winners = get_award_winners_data(api_calls, award_winners_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adi Shamir\n",
      "Alan Kay\n",
      "Alan Perlis\n",
      "Alfred Aho\n",
      "Allen Newell\n",
      "Amir Pnueli\n",
      "Andrew Yao\n",
      "Barbara Liskov\n",
      "Bob Kahn\n",
      "Butler Lampson\n",
      "Charles Bachman\n",
      "Charles P. Thacker\n",
      "Dana Scott\n",
      "David A. Patterson\n",
      "Dennis M. Ritchie\n",
      "Donald Knuth\n",
      "Douglas Engelbart\n",
      "E. Allen Emerson\n",
      "Edgar F. Codd\n",
      "Edmund M. Clarke\n",
      "Edsger W. Dijkstra\n",
      "Edward Feigenbaum\n",
      "Edwin Catmull\n",
      "Fernando J. Corbató\n",
      "Frances E. Allen\n",
      "Fred Brooks\n",
      "Geoffrey Hinton\n",
      "Herbert Simon\n",
      "Iosif Sifakis\n",
      "Ivan Sutherland\n",
      "Jack Dongarra\n",
      "James H. Wilkinson\n",
      "Jeffrey David Ullman\n",
      "Jim Gray\n",
      "John Backus\n",
      "John Cocke\n",
      "John Edward Hopcroft\n",
      "John L. Hennessy\n",
      "John McCarthy\n",
      "Judea Pearl\n",
      "Juris Hartmanis\n",
      "Ken Thompson\n",
      "Kenneth E. Iverson\n",
      "Kristen Nygaard\n",
      "Leonard Adleman\n",
      "Leslie Lamport\n",
      "Leslie Valiant\n",
      "Manuel Blum\n",
      "Martin Edward Hellman\n",
      "Marvin Minsky\n",
      "Maurice Wilkes\n",
      "Michael O. Rabin\n",
      "Michael Stonebraker\n",
      "Niklaus Wirth\n",
      "Ole-Johan Dahl\n",
      "Pat Hanrahan\n",
      "Peter Naur\n",
      "Raj Reddy\n",
      "Richard E. Stearns\n",
      "Richard Hamming\n",
      "Richard M. Karp\n",
      "Robert Tarjan\n",
      "Robert W. Floyd\n",
      "Robin Milner\n",
      "Ron Rivest\n",
      "Shafrira Goldwasser\n",
      "Silvio Micali\n",
      "Stephen Cook\n",
      "Tim Berners-Lee\n",
      "Tony Hoare\n",
      "Vint Cerf\n",
      "Whitfield Diffie\n",
      "William Kahan\n",
      "Yann LeCun\n",
      "Yoshua Bengio\n"
     ]
    }
   ],
   "source": [
    "for name in sorted(award_winners[\"name\"]):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_name</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_sentences</th>\n",
       "      <th>count_paragraphs</th>\n",
       "      <th>common_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[and, the, of, Bengio, for, is, a, work, deep,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robert Tarjan</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[and, Tarjan, is, the, of, University, at, Rob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael Stonebraker</td>\n",
       "      <td>162</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, Stonebraker, of, as, is, database, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stephen Cook</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[of, and, is, the, complexity, Department, Ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ron Rivest</td>\n",
       "      <td>123</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, of, the, is, Rivest, a, MIT, He, 's, at]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Manuel Blum</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, to, and, Manuel, Blum, born, 26, Apr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Richard M. Karp</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[in, and, the, of, for, Karp, is, computer, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Herbert Simon</td>\n",
       "      <td>175</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, and, was, in, science, to, political...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jeffrey David Ullman</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, as, and, of, are, computer, Stanford, kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Donald Knuth</td>\n",
       "      <td>182</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>[the, of, and, Knuth, computer, is, to, He, sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vint Cerf</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, and, is, Internet, National, Medal, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Geoffrey Hinton</td>\n",
       "      <td>176</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>[the, and, of, for, in, Hinton, a, his, to, is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>John McCarthy</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, of, and, He, McCarthy, was, scientist, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Marvin Minsky</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[and, of, AI, Minsky, the, Marvin, Lee, August...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Barbara Liskov</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, in, is, and, Liskov, computer, Barba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tony Hoare</td>\n",
       "      <td>142</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, Hoare, in, of, and, is, computer, has, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Niklaus Wirth</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[computer, a, several, languages, in, the, Nik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Edsger W. Dijkstra</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, was, of, his, in, Dijkstra, Dutch, 2002,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fred Brooks</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[the, of, computer, and, in, Brooks, was, soft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Shafrira Goldwasser</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[of, the, and, at, is, scientist, Science, Ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Leslie Lamport</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, and, of, in, systems, Lamport, distribut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Michael O. Rabin</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[and, Michael, Oser, Rabin, Hebrew, מִיכָאֵל, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>John Edward Hopcroft</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[of, the, and, at, University, John, Hopcroft,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pat Hanrahan</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, graphics, Computer, and, as, Patrick, M....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Allen Newell</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, and, of, 19, was, in, psychology, at, Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>David A. Patterson</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>[of, the, computer, RISC, is, and, Patterson, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ken Thompson</td>\n",
       "      <td>129</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, and, of, his, Thompson, computer, progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>John L. Hennessy</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[of, the, as, Hennessy, is, computer, in, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Andrew Yao</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[Yao, and, the, Chinese, is, a, of, for, Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Juris Hartmanis</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, July, computational, of, Juris, Hartmani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Alan Perlis</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, and, in, Ritchie, was, from, He, C, prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Adi Shamir</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, and, in, Ritchie, was, from, He, C, prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dennis M. Ritchie</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, and, in, Ritchie, was, from, He, C, prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Silvio Micali</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, Micali, of, and, cryptography, Silvio, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Douglas Engelbart</td>\n",
       "      <td>281</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>[the, of, and, in, Engelbart, was, his, at, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Martin Edward Hellman</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[and, to, the, Hellman, a, of, for, with, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Raj Reddy</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[of, the, He, is, in, to, and, Turing, Award, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Robert W. Floyd</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, a, of, in, Floyd, was, to, algorithm, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Amir Pnueli</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Amir, Pnueli, Hebrew, אמיר, פנואלי, April, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Alfred Aho</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[the, and, his, of, computer, programming, Aho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Leslie Valiant</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, a, in, the, of, Valiant, born, is, compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>John Backus</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[the, and, of, in, He, programming, his, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Edgar F. Codd</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[relational, for, the, management, computer, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Robin Milner</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[Milner, Robin, a, Arthur, John, Gorell, 13, J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Bob Kahn</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, Kahn, with, Vint, Cerf, Protocol, Intern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Leonard Adleman</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, of, is, He, for, Leonard, Adleman, born,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ivan Sutherland</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, of, in, computer, as, graphics, and, tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Richard Hamming</td>\n",
       "      <td>217</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>[the, Hamming, in, he, and, of, a, University,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Kenneth E. Iverson</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, for, of, programming, APL, in, and, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>E. Allen Emerson</td>\n",
       "      <td>123</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[and, of, the, is, Emerson, model, checking, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>John Cocke</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[computer, to, architecture, John, Cocke, May,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Kristen Nygaard</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, Nygaard, programming, and, August, compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Edwin Catmull</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, is, computer, of, Edwin, Earl, Ed, Catmu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Jim Gray</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[in, and, James, Nicholas, Gray, 1944, declare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Frances E. Allen</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, the, was, in, to, Allen, August, 4, an, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>William Kahan</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[in, and, the, William, Velvel, Morton, Kahan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Charles P. Thacker</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[computer, the, Charles, Patrick, Chuck, Thack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Judea Pearl</td>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, and, for, of, Pearl, is, on, a, in, Judea]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Fernando J. Corbató</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[July, a, Fernando, José, Corby, Corbató, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Butler Lampson</td>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, and, for, of, Pearl, is, on, a, in, Judea]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Ole-Johan Dahl</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Butler, W., Lampson, ForMemRS, born, December...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Yann LeCun</td>\n",
       "      <td>157</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>[of, the, and, is, He, computer, with, LeCun, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Tim Berners-Lee</td>\n",
       "      <td>348</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>[the, of, and, Web, He, a, is, as, World, Wide]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Iosif Sifakis</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[Joseph, Sifakis, Greek, Ιωσήφ, Σηφάκης, is, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Dana Scott</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, is, of, and, in, University, work, on, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Jack Dongarra</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, University, at, is, and, Computer, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Alan Kay</td>\n",
       "      <td>123</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, of, and, is, object-oriented, also, He, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Edmund M. Clarke</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[and, Clarke, was, for, the, Edmund, Melson, J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Richard E. Stearns</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, in, a, Stearns, is, University, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Edward Feigenbaum</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, of, is, Edward, Albert, Feigenbaum, born...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Peter Naur</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, a, He, to, Peter, Naur, 25, October, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>James H. Wilkinson</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, the, field, of, and, James, Hardy, Wilkins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Maurice Wilkes</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, a, Wilkes, was, who, and, unit, Sir,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Charles Bachman</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[his, Bachman, was, an, in, of, Charles, Willi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Whitfield Diffie</td>\n",
       "      <td>148</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, a, of, the, at, for, Diffie, key, as, is]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              winner_name  count_words  count_sentences  count_paragraphs  \\\n",
       "0           Yoshua Bengio           90                4                 3   \n",
       "1           Robert Tarjan           59                3                 1   \n",
       "2     Michael Stonebraker          162                7                 2   \n",
       "3            Stephen Cook           45                2                 1   \n",
       "4              Ron Rivest          123                8                 2   \n",
       "5             Manuel Blum           37                1                 2   \n",
       "6         Richard M. Karp           91                3                 2   \n",
       "7           Herbert Simon          175                7                 2   \n",
       "8    Jeffrey David Ullman           80                3                 2   \n",
       "9            Donald Knuth          182                8                 4   \n",
       "10              Vint Cerf           62                2                 2   \n",
       "11        Geoffrey Hinton          176                8                 4   \n",
       "12          John McCarthy           97                5                 3   \n",
       "13          Marvin Minsky           51                2                 3   \n",
       "14         Barbara Liskov          108                5                 2   \n",
       "15             Tony Hoare          142                7                 3   \n",
       "16          Niklaus Wirth           52                3                 2   \n",
       "17     Edsger W. Dijkstra          100                4                 2   \n",
       "18            Fred Brooks           95                3                 4   \n",
       "19    Shafrira Goldwasser           68                2                 2   \n",
       "20         Leslie Lamport          111                5                 1   \n",
       "21       Michael O. Rabin           23                1                 1   \n",
       "22   John Edward Hopcroft           78                3                 1   \n",
       "23           Pat Hanrahan           55                3                 2   \n",
       "24           Allen Newell           93                3                 1   \n",
       "25     David A. Patterson          160                8                 3   \n",
       "26           Ken Thompson          129                6                 3   \n",
       "27       John L. Hennessy          109                5                 2   \n",
       "28             Andrew Yao           81                5                 2   \n",
       "29        Juris Hartmanis           44                1                 2   \n",
       "30            Alan Perlis           99                5                 2   \n",
       "31             Adi Shamir           99                5                 2   \n",
       "32      Dennis M. Ritchie           99                5                 2   \n",
       "33          Silvio Micali           42                3                 2   \n",
       "34      Douglas Engelbart          281               10                 4   \n",
       "35  Martin Edward Hellman          111                4                 3   \n",
       "36              Raj Reddy          126                6                 2   \n",
       "37        Robert W. Floyd          112                6                 2   \n",
       "38            Amir Pnueli           22                1                 1   \n",
       "39             Alfred Aho           80                3                 4   \n",
       "40         Leslie Valiant           95                5                 2   \n",
       "41            John Backus          150                6                 4   \n",
       "42          Edgar F. Codd           66                2                 2   \n",
       "43           Robin Milner           31                1                 2   \n",
       "44               Bob Kahn           53                2                 2   \n",
       "45        Leonard Adleman           51                3                 1   \n",
       "46        Ivan Sutherland          150                6                 1   \n",
       "47        Richard Hamming          217                9                 4   \n",
       "48     Kenneth E. Iverson           73                2                 2   \n",
       "49       E. Allen Emerson          123                5                 3   \n",
       "50             John Cocke           37                2                 1   \n",
       "51        Kristen Nygaard           52                3                 2   \n",
       "52          Edwin Catmull           44                2                 2   \n",
       "53               Jim Gray           36                1                 1   \n",
       "54       Frances E. Allen           69                4                 2   \n",
       "55          William Kahan           46                1                 1   \n",
       "56     Charles P. Thacker           33                2                 1   \n",
       "57            Judea Pearl          154                5                 3   \n",
       "58    Fernando J. Corbató           26                1                 1   \n",
       "59         Butler Lampson          154                5                 3   \n",
       "60         Ole-Johan Dahl           27                1                 1   \n",
       "61             Yann LeCun          157                7                 4   \n",
       "62        Tim Berners-Lee          348               17                 5   \n",
       "63          Iosif Sifakis           30                2                 2   \n",
       "64             Dana Scott           83                3                 1   \n",
       "65          Jack Dongarra          113                5                 2   \n",
       "66               Alan Kay          123                7                 3   \n",
       "67       Edmund M. Clarke           59                3                 1   \n",
       "68     Richard E. Stearns          119                6                 2   \n",
       "69      Edward Feigenbaum           36                2                 1   \n",
       "70             Peter Naur           51                3                 2   \n",
       "71     James H. Wilkinson           37                1                 2   \n",
       "72         Maurice Wilkes           69                2                 2   \n",
       "73        Charles Bachman           56                3                 1   \n",
       "74       Whitfield Diffie          148                6                 2   \n",
       "\n",
       "                                         common_words  \n",
       "0   [and, the, of, Bengio, for, is, a, work, deep,...  \n",
       "1   [and, Tarjan, is, the, of, University, at, Rob...  \n",
       "2   [and, Stonebraker, of, as, is, database, the, ...  \n",
       "3   [of, and, is, the, complexity, Department, Ste...  \n",
       "4      [and, of, the, is, Rivest, a, MIT, He, 's, at]  \n",
       "5   [the, of, to, and, Manuel, Blum, born, 26, Apr...  \n",
       "6   [in, and, the, of, for, Karp, is, computer, th...  \n",
       "7   [the, of, and, was, in, science, to, political...  \n",
       "8   [the, as, and, of, are, computer, Stanford, kn...  \n",
       "9   [the, of, and, Knuth, computer, is, to, He, sc...  \n",
       "10  [the, of, and, is, Internet, National, Medal, ...  \n",
       "11    [the, and, of, for, in, Hinton, a, his, to, is]  \n",
       "12  [the, of, and, He, McCarthy, was, scientist, a...  \n",
       "13  [and, of, AI, Minsky, the, Marvin, Lee, August...  \n",
       "14  [the, of, in, is, and, Liskov, computer, Barba...  \n",
       "15  [the, Hoare, in, of, and, is, computer, has, t...  \n",
       "16  [computer, a, several, languages, in, the, Nik...  \n",
       "17  [the, was, of, his, in, Dijkstra, Dutch, 2002,...  \n",
       "18  [the, of, computer, and, in, Brooks, was, soft...  \n",
       "19  [of, the, and, at, is, scientist, Science, Ins...  \n",
       "20  [the, and, of, in, systems, Lamport, distribut...  \n",
       "21  [and, Michael, Oser, Rabin, Hebrew, מִיכָאֵל, ...  \n",
       "22  [of, the, and, at, University, John, Hopcroft,...  \n",
       "23  [the, graphics, Computer, and, as, Patrick, M....  \n",
       "24  [the, and, of, 19, was, in, psychology, at, Sc...  \n",
       "25  [of, the, computer, RISC, is, and, Patterson, ...  \n",
       "26  [the, and, of, his, Thompson, computer, progra...  \n",
       "27  [of, the, as, Hennessy, is, computer, in, and,...  \n",
       "28  [Yao, and, the, Chinese, is, a, of, for, Scien...  \n",
       "29  [the, July, computational, of, Juris, Hartmani...  \n",
       "30  [the, and, in, Ritchie, was, from, He, C, prog...  \n",
       "31  [the, and, in, Ritchie, was, from, He, C, prog...  \n",
       "32  [the, and, in, Ritchie, was, from, He, C, prog...  \n",
       "33  [the, Micali, of, and, cryptography, Silvio, b...  \n",
       "34  [the, of, and, in, Engelbart, was, his, at, to...  \n",
       "35  [and, to, the, Hellman, a, of, for, with, is, ...  \n",
       "36  [of, the, He, is, in, to, and, Turing, Award, ...  \n",
       "37  [the, a, of, in, Floyd, was, to, algorithm, fo...  \n",
       "38  [Amir, Pnueli, Hebrew, אמיר, פנואלי, April, 22...  \n",
       "39  [the, and, his, of, computer, programming, Aho...  \n",
       "40  [and, a, in, the, of, Valiant, born, is, compu...  \n",
       "41  [the, and, of, in, He, programming, his, for, ...  \n",
       "42  [relational, for, the, management, computer, m...  \n",
       "43  [Milner, Robin, a, Arthur, John, Gorell, 13, J...  \n",
       "44  [the, Kahn, with, Vint, Cerf, Protocol, Intern...  \n",
       "45  [the, of, is, He, for, Leonard, Adleman, born,...  \n",
       "46  [the, of, in, computer, as, graphics, and, tha...  \n",
       "47  [the, Hamming, in, he, and, of, a, University,...  \n",
       "48  [the, for, of, programming, APL, in, and, to, ...  \n",
       "49  [and, of, the, is, Emerson, model, checking, i...  \n",
       "50  [computer, to, architecture, John, Cocke, May,...  \n",
       "51  [the, Nygaard, programming, and, August, compu...  \n",
       "52  [the, is, computer, of, Edwin, Earl, Ed, Catmu...  \n",
       "53  [in, and, James, Nicholas, Gray, 1944, declare...  \n",
       "54  [and, the, was, in, to, Allen, August, 4, an, ...  \n",
       "55  [in, and, the, William, Velvel, Morton, Kahan,...  \n",
       "56  [computer, the, Charles, Patrick, Chuck, Thack...  \n",
       "57   [the, and, for, of, Pearl, is, on, a, in, Judea]  \n",
       "58  [July, a, Fernando, José, Corby, Corbató, 1, 1...  \n",
       "59   [the, and, for, of, Pearl, is, on, a, in, Judea]  \n",
       "60  [Butler, W., Lampson, ForMemRS, born, December...  \n",
       "61  [of, the, and, is, He, computer, with, LeCun, ...  \n",
       "62    [the, of, and, Web, He, a, is, as, World, Wide]  \n",
       "63  [Joseph, Sifakis, Greek, Ιωσήφ, Σηφάκης, is, a...  \n",
       "64  [the, is, of, and, in, University, work, on, t...  \n",
       "65  [the, of, University, at, is, and, Computer, S...  \n",
       "66  [the, of, and, is, object-oriented, also, He, ...  \n",
       "67  [and, Clarke, was, for, the, Edmund, Melson, J...  \n",
       "68  [the, of, in, a, Stearns, is, University, with...  \n",
       "69  [the, of, is, Edward, Albert, Feigenbaum, born...  \n",
       "70  [the, a, He, to, Peter, Naur, 25, October, 192...  \n",
       "71  [a, the, field, of, and, James, Hardy, Wilkins...  \n",
       "72  [the, of, a, Wilkes, was, who, and, unit, Sir,...  \n",
       "73  [his, Bachman, was, an, in, of, Charles, Willi...  \n",
       "74    [and, a, of, the, at, for, Diffie, key, as, is]  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award_winners_intro = pd.DataFrame(columns=[\"winner_name\", \"count_words\", \"count_sentences\", \"count_paragraphs\", \"common_words\"])\n",
    "award_winners_intro[\"winner_name\"] = award_winners[\"name\"]\n",
    "\n",
    "def get_intro_stats(intro): \n",
    "    intro_html = BeautifulSoup(intro, \"html.parser\")\n",
    "    intro_text = intro_html.get_text(\" \")\n",
    "    count_words = sum([word.strip(string.punctuation).isalnum() for word in intro_text.split()])\n",
    "    count_sentences = len(sent_tokenize(intro_text))\n",
    "    count_paragraphs = len(intro_html.find_all(\"p\"))\n",
    "    word_filter = set(list(string.punctuation) + [\"``\", \"''\", \"–\"])\n",
    "    word_freqdist= nltk.FreqDist([word for word in word_tokenize(intro_text) if word not in word_filter]).most_common(10)\n",
    "    common_words = [word[0] for word in word_freqdist]\n",
    "    return count_words, count_sentences, count_paragraphs, common_words\n",
    "\n",
    "intro_stats = {\"word_count\": [], \"sentence_count\": [], \"paragraph_count\": [], \"common_words\": []}\n",
    "for intro in award_winners[\"intro\"]:\n",
    "    count_word, count_sentences, count_paragraphs, common_words = get_intro_stats(intro)\n",
    "    intro_stats[\"word_count\"].append(count_word)\n",
    "    intro_stats[\"sentence_count\"].append(count_sentences)\n",
    "    intro_stats[\"paragraph_count\"].append(count_paragraphs)\n",
    "    intro_stats[\"common_words\"].append(common_words)\n",
    "\n",
    "award_winners_intro[\"count_words\"] = intro_stats[\"word_count\"]\n",
    "award_winners_intro[\"count_sentences\"] = intro_stats[\"sentence_count\"]\n",
    "award_winners_intro[\"count_paragraphs\"] = intro_stats[\"paragraph_count\"]\n",
    "award_winners_intro[\"common_words\"] = intro_stats[\"common_words\"]\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "award_winners_intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       winner_name  count_words  count_sentences  count_paragraphs  \\\n",
      "0  Tim Berners-Lee          348               17                 4   \n",
      "1    Yoshua Bengio           90                4                 2   \n",
      "2  Geoffrey Hinton          176                8                 3   \n",
      "3     Donald Knuth          182                8                 3   \n",
      "4  Richard M. Karp           91                3                 2   \n",
      "5    Robert Tarjan           59                3                 1   \n",
      "6        Vint Cerf           62                2                 1   \n",
      "7      Judea Pearl          154                5                 2   \n",
      "8    Herbert Simon          175                7                 2   \n",
      "9    Marvin Minsky           51                2                 2   \n",
      "\n",
      "                                        common_words  \\\n",
      "0    [the, of, and, Web, He, a, is, as, World, Wide]   \n",
      "1  [and, the, of, Bengio, for, is, a, work, deep,...   \n",
      "2    [the, and, of, for, in, Hinton, a, his, to, is]   \n",
      "3  [the, of, and, Knuth, computer, is, to, He, sc...   \n",
      "4  [in, and, the, of, for, Karp, is, computer, th...   \n",
      "5  [and, Tarjan, is, the, of, University, at, Rob...   \n",
      "6  [the, of, and, is, Internet, National, Medal, ...   \n",
      "7   [the, and, for, of, Pearl, is, on, a, in, Judea]   \n",
      "8  [the, of, and, was, in, science, to, political...   \n",
      "9  [and, of, AI, Minsky, the, Marvin, Lee, August...   \n",
      "\n",
      "                    common_words_after_preprocessing  \n",
      "0  [Web, He, World, Wide, Berners-Lee, 's, Comput...  \n",
      "1  [Bengio, work, deep, learning, Learning, Hinto...  \n",
      "2  [Hinton, computer, work, neural, networks, Goo...  \n",
      "3  [Knuth, computer, He, science, analysis, algor...  \n",
      "4  [Karp, computer, theory, algorithms, Richard, ...  \n",
      "5  [Tarjan, University, Robert, Endre, born, Apri...  \n",
      "6  [Internet, National, Medal, Vinton, Gray, Cerf...  \n",
      "7  [Pearl, Judea, computer, probabilistic, artifi...  \n",
      "8  [science, political, computer, He, Simon, 2001...  \n",
      "9  [AI, Minsky, Marvin, Lee, August, 9, 1927, Jan...  \n"
     ]
    }
   ],
   "source": [
    "def process_common_words(intro):\n",
    "    intro_text = BeautifulSoup(intro, \"html.parser\").get_text(\" \")\n",
    "    word_filter = set(stopwords.words('english') + list(string.punctuation) + [\"``\", \"''\", \"–\"])\n",
    "    tokenized_intro = word_tokenize(intro_text)\n",
    "    word_freqdist = nltk.FreqDist([word for word in tokenized_intro if word not in word_filter]).most_common(10)\n",
    "    common_words = [word[0] for word in word_freqdist]\n",
    "    return common_words\n",
    "\n",
    "common_words_after_preprocessing = [process_common_words(intro) for intro in award_winners[\"intro\"]]\n",
    "award_winners_intro[\"common_words_after_preprocessing\"] = common_words_after_preprocessing\n",
    "\n",
    "print(award_winners_intro.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Sub Activity\n",
    "\n",
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_intro_text = \" \".join([BeautifulSoup(intro, \"html.parser\").get_text(\" \") for intro in award_winners[\"intro\"]])\n",
    "\n",
    "word_filter = set(stopwords.words('english') + list(string.punctuation) + [\"``\", \"''\", \"–\"])\n",
    "tokenized_intro = word_tokenize(long_intro_text)\n",
    "intro_words = [word for word in tokenized_intro if word not in word_filter]\n",
    "\n",
    "print(\"Number of unique words before stemming with Porter Stemmer: {}\".format(len(list(nltk.FreqDist(intro_words)))))\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "intro_words = [porter_stemmer.stem(word) for word in intro_words]\n",
    "\n",
    "print(\"Number of unique words after stemming with Porter Stemmer: {}\".format(len(list(nltk.FreqDist(intro_words)))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_intro_text = \" \".join([BeautifulSoup(intro, \"html.parser\").get_text(\" \") for intro in award_winners[\"intro\"]])\n",
    "\n",
    "word_filter = set(stopwords.words('english') + list(string.punctuation) + [\"``\", \"''\", \"–\"])\n",
    "tokenized_intro = word_tokenize(long_intro_text)\n",
    "intro_words = [word for word in tokenized_intro if word not in word_filter]\n",
    "\n",
    "print(\"Number of unique words before stemming with Snowball Stemmer: {}\".format(len(list(nltk.FreqDist(intro_words)))))\n",
    "\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "intro_words = [snow_stemmer.stem(word) for word in intro_words]\n",
    "\n",
    "print(\"Number of unique words after stemming with Snowball Stemmer: {}\".format(len(list(nltk.FreqDist(intro_words)))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words before lemmatization with Word Net Lemmatizer: 1766\n",
      "Number of unique words after lemmatization with Word Net Lemmatizer: 1715\n"
     ]
    }
   ],
   "source": [
    "long_intro_text = \" \".join([BeautifulSoup(intro, \"html.parser\").get_text(\" \") for intro in award_winners[\"intro\"]])\n",
    "\n",
    "word_filter = set(stopwords.words('english') + list(string.punctuation) + [\"``\", \"''\", \"–\"])\n",
    "tokenized_intro = word_tokenize(long_intro_text)\n",
    "intro_words = [word for word in tokenized_intro if word not in word_filter]\n",
    "\n",
    "print(\"Number of unique words before lemmatization with Word Net Lemmatizer: {}\".format(len(list(nltk.FreqDist(intro_words)))))\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "intro_words = [wordnet_lemmatizer.lemmatize(word) for word in intro_words]\n",
    "\n",
    "print(\"Number of unique words after lemmatization with Word Net Lemmatizer: {}\".format(len(list(nltk.FreqDist(intro_words)))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       winner_name  count_words  count_sentences  count_paragraphs  \\\n",
      "0  Tim Berners-Lee          348               17                 4   \n",
      "1    Yoshua Bengio           90                4                 2   \n",
      "2  Geoffrey Hinton          176                8                 3   \n",
      "3     Donald Knuth          182                8                 3   \n",
      "4  Richard M. Karp           91                3                 2   \n",
      "5    Robert Tarjan           59                3                 1   \n",
      "6        Vint Cerf           62                2                 1   \n",
      "7      Judea Pearl          154                5                 2   \n",
      "8    Herbert Simon          175                7                 2   \n",
      "9    Marvin Minsky           51                2                 2   \n",
      "\n",
      "                                        common_words  \\\n",
      "0    [the, of, and, Web, He, a, is, as, World, Wide]   \n",
      "1  [and, the, of, Bengio, for, is, a, work, deep,...   \n",
      "2    [the, and, of, for, in, Hinton, a, his, to, is]   \n",
      "3  [the, of, and, Knuth, computer, is, to, He, sc...   \n",
      "4  [in, and, the, of, for, Karp, is, computer, th...   \n",
      "5  [and, Tarjan, is, the, of, University, at, Rob...   \n",
      "6  [the, of, and, is, Internet, National, Medal, ...   \n",
      "7   [the, and, for, of, Pearl, is, on, a, in, Judea]   \n",
      "8  [the, of, and, was, in, science, to, political...   \n",
      "9  [and, of, AI, Minsky, the, Marvin, Lee, August...   \n",
      "\n",
      "                    common_words_after_preprocessing  \\\n",
      "0  [Web, He, World, Wide, Berners-Lee, 's, Comput...   \n",
      "1  [Bengio, work, deep, learning, Learning, Hinto...   \n",
      "2  [Hinton, computer, work, neural, networks, Goo...   \n",
      "3  [Knuth, computer, He, science, analysis, algor...   \n",
      "4  [Karp, computer, theory, algorithms, Richard, ...   \n",
      "5  [Tarjan, University, Robert, Endre, born, Apri...   \n",
      "6  [Internet, National, Medal, Vinton, Gray, Cerf...   \n",
      "7  [Pearl, Judea, computer, probabilistic, artifi...   \n",
      "8  [science, political, computer, He, Simon, 2001...   \n",
      "9  [AI, Minsky, Marvin, Lee, August, 9, 1927, Jan...   \n",
      "\n",
      "                                            synonyms  \\\n",
      "0  [web, web, entanglement, vane, web, network, w...   \n",
      "1  [work, work, piece_of_work, employment, work, ...   \n",
      "2  [computer, computing_machine, computing_device...   \n",
      "3  [computer, computing_machine, computing_device...   \n",
      "4  [computer, computing_machine, computing_device...   \n",
      "5  [university, university, university, Robert, H...   \n",
      "6  [internet, net, cyberspace, national, subject,...   \n",
      "7  [pearl, bone, ivory, pearl, off-white, drop, b...   \n",
      "8  [science, scientific_discipline, skill, scienc...   \n",
      "9  [Army_Intelligence, AI, artificial_intelligenc...   \n",
      "\n",
      "                                           antonyms  \n",
      "0            [narrow, narrow, middle, last, second]  \n",
      "1     [idle, malfunction, shallow, shallow, unborn]  \n",
      "2             [idle, malfunction, shallow, shallow]  \n",
      "3                                       [synthesis]  \n",
      "4                                          [unborn]  \n",
      "5                                          [unborn]  \n",
      "6                    [international, local, unborn]  \n",
      "7  [natural, stupidity, devolution, nondevelopment]  \n",
      "8                                    [nonpolitical]  \n",
      "9                                        [windward]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_210/3179988525.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  award_winners_intro[\"synonyms\"][i] = synonyms\n",
      "/tmp/ipykernel_210/3179988525.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  award_winners_intro[\"antonyms\"][i] = antonyms\n"
     ]
    }
   ],
   "source": [
    "award_winners_intro = award_winners_intro.assign(synonyms = np.nan, antonyms = np.nan)\n",
    "common_words_after_preprocessing = award_winners_intro[\"common_words_after_preprocessing\"]\n",
    "\n",
    "def get_synonyms_antonyms(common_words):\n",
    "    synonyms = []\n",
    "    antonyms = []\n",
    "    for word in common_words:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "                if l.antonyms():\n",
    "                    antonyms.append(l.antonyms()[0].name())\n",
    "    return synonyms, antonyms\n",
    "\n",
    "for i in range(len(common_words_after_preprocessing)):\n",
    "    synonyms, antonyms = get_synonyms_antonyms(common_words_after_preprocessing[i])\n",
    "    award_winners_intro[\"synonyms\"][i] = synonyms\n",
    "    award_winners_intro[\"antonyms\"][i] = antonyms\n",
    "\n",
    "print(award_winners_intro.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334b9cbccb391e97a610fa1686459925ba3c38a6dfd8a581da5ac585bc22844f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
