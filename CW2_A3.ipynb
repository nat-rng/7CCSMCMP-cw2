{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from urllib.parse import unquote\n",
    "\n",
    "WIKIDATA_API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "WIKIPEDIA_API_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"cw_query/2.0\"}\n",
    "\n",
    "PARAMS_QUERY_SEARCH = {\n",
    "    \"action\":\"query\",\n",
    "    \"format\":\"json\",\n",
    "    \"formatversion\":\"latest\",\n",
    "    \"list\":\"search\",\n",
    "    \"srsearch\": \"haswbstatement:P166=Q185667\",\n",
    "    \"srlimit\":\"max\"\n",
    "}\n",
    "\n",
    "PARAMS_GETCONTENT={\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",\n",
    "    \"prop\": \"extracts\",\n",
    "    \"explaintext\": True,\n",
    "}\n",
    "\n",
    "PARAMS_WBGETENTITIES_LABELS = {\n",
    "    \"action\": \"wbgetentities\",\n",
    "    \"format\": \"json\",\n",
    "    \"ids\": \"\",\n",
    "    \"sites\": \"\",\n",
    "    \"props\": \"labels\",\n",
    "    \"languages\": \"en\",\n",
    "    \"sitefilter\": \"enwiki\",\n",
    "    \"utf8\": 1,\n",
    "    \"ascii\": 1,\n",
    "    \"formatversion\": \"latest\"\n",
    "}\n",
    "\n",
    "PARAMS_WBGETENTITIES_SITES = {\n",
    "    \"action\": \"wbgetentities\",\n",
    "    \"format\": \"json\",\n",
    "    \"ids\": \"\",\n",
    "    \"sites\": \"\",\n",
    "    \"props\": \"sitelinks/urls\",\n",
    "    \"languages\": \"en\",\n",
    "    \"sitefilter\": \"enwiki\",\n",
    "    \"utf8\": 1,\n",
    "    \"ascii\": 1,\n",
    "    \"formatversion\": \"latest\"\n",
    "}\n",
    "\n",
    "PARAMS_WBGETENTITIES_CLAIMS = {\n",
    "    \"action\": \"wbgetentities\",\n",
    "    \"format\": \"json\",\n",
    "    \"ids\": \"\",\n",
    "    \"props\": \"claims\",\n",
    "    \"languages\": \"en\",\n",
    "    \"sitefilter\": \"\",\n",
    "    \"formatversion\": \"latest\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turing_award_recipients():\n",
    "    acm_award_entities = []\n",
    "    search_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_QUERY_SEARCH)\n",
    "    data = search_response.json()\n",
    "    for result in data['query']['search']:\n",
    "        acm_award_entities.append(result['title'])\n",
    "    return acm_award_entities\n",
    "\n",
    "get_turing_award_recipients()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_content(entity_id):\n",
    "    PARAMS_WBGETENTITIES_SITES[\"ids\"] = entity_id\n",
    "    wbgetentities_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_WBGETENTITIES_SITES)\n",
    "    wbgetentities_data = wbgetentities_response.json()\n",
    "    recipient_name = wbgetentities_data[\"entities\"][entity_id][\"sitelinks\"][\"enwiki\"][\"url\"].split(\"https://en.wikipedia.org/wiki/\")[1]\n",
    "\n",
    "    PARAMS_GETCONTENT[\"titles\"] = unquote(recipient_name)\n",
    "    wbgetentities_response = requests.get(WIKIPEDIA_API_ENDPOINT, headers=HEADERS, params=PARAMS_GETCONTENT)\n",
    "    wbgetentities_data = wbgetentities_response.json()\n",
    "    content = next(iter(wbgetentities_data[\"query\"][\"pages\"].values()))[\"extract\"]\n",
    "    return content\n",
    "\n",
    "print(get_wikipedia_content(\"Q92625\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_data_dict = {\"gender\": \"P21\", \"birth_date\": \"P569\", \"birth_city\": \"P19\", \n",
    "                  \"birth_country\": \"P17\", \"employer\": \"P108\", \"educated_at\": \"P69\"}\n",
    "\n",
    "def get_wikidata_label(entity_id):\n",
    "    PARAMS_WBGETENTITIES_LABELS[\"ids\"] = entity_id\n",
    "    wbgetentities_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_WBGETENTITIES_LABELS)\n",
    "    wbgetentities_data = wbgetentities_response.json()\n",
    "    labels = next(iter(wbgetentities_data[\"entities\"].values()))[\"labels\"]\n",
    "    value = labels[\"en\"][\"value\"]\n",
    "    return value\n",
    "\n",
    "def get_wikidata_claims(entity_id):\n",
    "    PARAMS_WBGETENTITIES_CLAIMS[\"ids\"] = entity_id\n",
    "    wbgetentities_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_WBGETENTITIES_CLAIMS)\n",
    "    wbgetentities_data = wbgetentities_response.json()\n",
    "    claims = next(iter(wbgetentities_data[\"entities\"].values()))[\"claims\"]\n",
    "    return claims\n",
    "\n",
    "def get_dict_values(entity_id):\n",
    "    claims = get_wikidata_claims(entity_id)\n",
    "    try:\n",
    "        name = get_wikidata_label(entity_id)\n",
    "    except KeyError:\n",
    "        name = None\n",
    "    try:\n",
    "        intro = get_wikipedia_content(entity_id).split(\"\\n\\n\\n\")[0]\n",
    "    except KeyError:\n",
    "        intro = None   \n",
    "    try: \n",
    "        gender = get_wikidata_label(claims[wiki_data_dict[\"gender\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "    except KeyError:\n",
    "        gender = None\n",
    "    try:\n",
    "        birth_date = datetime.strptime(claims[wiki_data_dict[\"birth_date\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"time\"], \"+%Y-%m-%dT%XZ\").strftime(\"%d %B %Y\")\n",
    "    except ValueError:\n",
    "        birth_date = datetime.strptime(claims[wiki_data_dict[\"birth_date\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"time\"], \"+%Y-00-00T%XZ\").strftime(\"%Y\")\n",
    "    except KeyError:\n",
    "        birth_date = None\n",
    "    try:\n",
    "        birth_city = get_wikidata_label(claims[wiki_data_dict[\"birth_city\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "        birth_city_claims = get_wikidata_claims(claims[wiki_data_dict[\"birth_city\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "        birth_country = get_wikidata_label(birth_city_claims[wiki_data_dict[\"birth_country\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "        birth_place = \"{}, {}\".format(birth_city, birth_country)\n",
    "    except KeyError:\n",
    "        birth_place = None\n",
    "    try:\n",
    "        employer_list = []\n",
    "        if len(claims[wiki_data_dict[\"employer\"]]) == 1:\n",
    "            employer = get_wikidata_label(claims[wiki_data_dict[\"employer\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "        else:\n",
    "            for i in range(len(claims[wiki_data_dict[\"employer\"]])):\n",
    "                employer = get_wikidata_label(claims[wiki_data_dict[\"employer\"]][i][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "                employer_list.append(employer)\n",
    "            employer = employer_list\n",
    "    except KeyError:\n",
    "        employer = None\n",
    "    try:\n",
    "        education_list = []\n",
    "        if len(claims[wiki_data_dict[\"educated_at\"]]) == 1:\n",
    "            education = get_wikidata_label(claims[wiki_data_dict[\"educated_at\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "        else:\n",
    "            for i in range(len(claims[wiki_data_dict[\"educated_at\"]])):\n",
    "                education = get_wikidata_label(claims[wiki_data_dict[\"educated_at\"]][i][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"])\n",
    "                education_list.append(education)\n",
    "            education = education_list\n",
    "    except KeyError:\n",
    "        education = None\n",
    "    return name, intro, gender, birth_date, birth_place, employer, education\n",
    "\n",
    "\n",
    "award_winners = {\"name\": [], \"intro\": [], \"gender\": [], \"birth_date\": [], \n",
    "                    \"birth_place\": [], \"employer\": [], \"educated_at\": []}\n",
    "acm_award_winners = get_turing_award_recipients()\n",
    "for entity_id in acm_award_winners:\n",
    "    print(entity_id)\n",
    "    name, intro, gender, birth_date, birth_place, employer, education = get_dict_values(entity_id)\n",
    "    award_winners[\"name\"].append(name)\n",
    "    award_winners[\"intro\"].append(intro)\n",
    "    award_winners[\"gender\"].append(gender)\n",
    "    award_winners[\"birth_date\"].append(birth_date)\n",
    "    award_winners[\"birth_place\"].append(birth_place)\n",
    "    award_winners[\"employer\"].append(employer)\n",
    "    award_winners[\"educated_at\"].append(education)\n",
    "\n",
    "print(award_winners)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adi Shamir\n",
      "Alan Kay\n",
      "Alan Perlis\n",
      "Alfred Aho\n",
      "Allen Newell\n",
      "Amir Pnueli\n",
      "Andrew Yao\n",
      "Barbara Liskov\n",
      "Bob Kahn\n",
      "Butler Lampson\n",
      "Charles Bachman\n",
      "Charles P. Thacker\n",
      "Dana Scott\n",
      "David A. Patterson\n",
      "Dennis M. Ritchie\n",
      "Donald Knuth\n",
      "Douglas Engelbart\n",
      "E. Allen Emerson\n",
      "Edgar F. Codd\n",
      "Edmund M. Clarke\n",
      "Edsger W. Dijkstra\n",
      "Edward Feigenbaum\n",
      "Edwin Catmull\n",
      "Fernando J. Corbat√≥\n",
      "Frances E. Allen\n",
      "Fred Brooks\n",
      "Geoffrey Hinton\n",
      "Herbert Simon\n",
      "Iosif Sifakis\n",
      "Ivan Sutherland\n",
      "Jack Dongarra\n",
      "James H. Wilkinson\n",
      "Jeffrey David Ullman\n",
      "Jim Gray\n",
      "John Backus\n",
      "John Cocke\n",
      "John Edward Hopcroft\n",
      "John L. Hennessy\n",
      "John McCarthy\n",
      "Judea Pearl\n",
      "Juris Hartmanis\n",
      "Ken Thompson\n",
      "Kenneth E. Iverson\n",
      "Kristen Nygaard\n",
      "Leonard Adleman\n",
      "Leslie Lamport\n",
      "Leslie Valiant\n",
      "Manuel Blum\n",
      "Martin Edward Hellman\n",
      "Marvin Minsky\n",
      "Maurice Wilkes\n",
      "Michael O. Rabin\n",
      "Michael Stonebraker\n",
      "Niklaus Wirth\n",
      "Ole-Johan Dahl\n",
      "Pat Hanrahan\n",
      "Peter Naur\n",
      "Raj Reddy\n",
      "Richard E. Stearns\n",
      "Richard Hamming\n",
      "Richard M. Karp\n",
      "Robert Tarjan\n",
      "Robert W. Floyd\n",
      "Robin Milner\n",
      "Ron Rivest\n",
      "Shafrira Goldwasser\n",
      "Silvio Micali\n",
      "Stephen Cook\n",
      "Tim Berners-Lee\n",
      "Tony Hoare\n",
      "Vint Cerf\n",
      "Whitfield Diffie\n",
      "William Kahan\n",
      "Yann LeCun\n",
      "Yoshua Bengio\n"
     ]
    }
   ],
   "source": [
    "for name in sorted(award_winners[\"name\"]):\n",
    "    print(name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334b9cbccb391e97a610fa1686459925ba3c38a6dfd8a581da5ac585bc22844f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
