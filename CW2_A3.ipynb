{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nat_rng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/nat_rng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/nat_rng/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/nat_rng/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from datetime import datetime\n",
    "from urllib.parse import unquote\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED\n",
    "from collections import OrderedDict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "WIKIDATA_API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "WIKIPEDIA_API_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"uni_coursework/2.0; nat.1.roongjirarat@kcl.ac.uk\"}\n",
    "\n",
    "PARAMS_QUERY_SEARCH = {\n",
    "    \"action\":\"query\",\n",
    "    \"format\":\"json\",\n",
    "    \"formatversion\":\"latest\",\n",
    "    \"list\":\"search\",\n",
    "    \"srsearch\": \"haswbstatement:P166=Q185667\",\n",
    "    \"srlimit\":\"max\"\n",
    "}\n",
    "\n",
    "PARAMS_GETCONTENT = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",\n",
    "    \"prop\": \"extracts\",\n",
    "    \"exlimit\": \"max\"\n",
    "}\n",
    "\n",
    "PARAMS_WBGETENTITIES_LABELS = {\n",
    "    \"action\": \"wbgetentities\",\n",
    "    \"format\": \"json\",\n",
    "    \"ids\": \"\",\n",
    "    \"sites\": \"\",\n",
    "    \"props\": \"labels\",\n",
    "    \"languages\": \"en\",\n",
    "    \"sitefilter\": \"enwiki\",\n",
    "    \"utf8\": 1,\n",
    "    \"ascii\": 1,\n",
    "    \"formatversion\": \"latest\"\n",
    "}\n",
    "\n",
    "PARAMS_WBGETENTITIES_SITES = {\n",
    "    \"action\": \"wbgetentities\",\n",
    "    \"format\": \"json\",\n",
    "    \"ids\": \"\",\n",
    "    \"sites\": \"\",\n",
    "    \"props\": \"sitelinks/urls\",\n",
    "    \"languages\": \"en\",\n",
    "    \"sitefilter\": \"enwiki\",\n",
    "    \"utf8\": 1,\n",
    "    \"ascii\": 1,\n",
    "    \"formatversion\": \"latest\"\n",
    "}\n",
    "\n",
    "PARAMS_WBGETENTITIES_CLAIMS = {\n",
    "    \"action\": \"wbgetentities\",\n",
    "    \"format\": \"json\",\n",
    "    \"ids\": \"\",\n",
    "    \"props\": \"claims\",\n",
    "    \"languages\": \"en\",\n",
    "    \"sitefilter\": \"\",\n",
    "    \"formatversion\": \"latest\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q80', 'Q3572699', 'Q92894', 'Q17457', 'Q92612', 'Q92638', 'Q92743', 'Q92824', 'Q181529', 'Q204815', 'Q578036', 'Q92794', 'Q92739', 'Q49823', 'Q92602', 'Q3571662', 'Q92626', 'Q92758', 'Q16080922', 'Q62870', 'Q8556', 'Q92604', 'Q357965', 'Q11609', 'Q92609', 'Q439245', 'Q92670', 'Q92819', 'Q92851', 'Q92613', 'Q62874', 'Q92854', 'Q92628', 'Q7143512', 'Q62861', 'Q320624', 'Q45575', 'Q1107006', 'Q92614', 'Q62888', 'Q93080', 'Q476466', 'Q92820', 'Q92649', 'Q62898', 'Q92641', 'Q92742', 'Q93154', 'Q62843', 'Q92643', 'Q92823', 'Q462089', 'Q62866', 'Q92629', 'Q92618', 'Q92822', 'Q92596', 'Q92746', 'Q918650', 'Q62857', 'Q92619', 'Q92821', 'Q62877', 'Q92781', 'Q92782', 'Q92632', 'Q93161', 'Q92744', 'Q92606', 'Q9602', 'Q92625', 'Q62894', 'Q92644', 'Q92745', 'Q92828']\n"
     ]
    }
   ],
   "source": [
    "def get_turing_award_recipients():\n",
    "    acm_award_entities = []\n",
    "    search_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_QUERY_SEARCH)\n",
    "    data = search_response.json()\n",
    "    for result in data['query']['search']:\n",
    "        acm_award_entities.append(result['title'])\n",
    "    return acm_award_entities\n",
    "\n",
    "print(get_turing_award_recipients())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<p><b>Patrick M. Hanrahan</b> (born 1954) is an American computer graphics researcher, the Canon USA Professor of Computer Science and Electrical Engineering in the Computer Graphics Laboratory at Stanford University.\n",
      "His research focuses on rendering algorithms, graphics processing units, as well as scientific illustration and visualization. He has received numerous awards, including the 2019 Turing Award.\n",
      "</p>\n",
      "<h2><span id=\"Education_and_academic_work\">Education and academic work</span></h2>\n",
      "<p>Hanrahan grew up in Green Bay, Wisconsin. He attended the University of Wisconsin–Madison and graduated with a B.S. in nuclear engineering in 1977, continued his education there, and as a graduate student taught a new computer science course in graphics in 1981. One of his first students was an art graduate student, Donna Cox, now known for her art and scientific visualizations. In the 1980s he went to work at the New York Institute of Technology Computer Graphics Laboratory and at Digital Equipment Corporation under Edwin Catmull. He returned to U.W. Madison and completed his Ph.D. in biophysics in 1985.</p>\n",
      "<h2><span id=\"Career\">Career</span></h2>\n",
      "<p>As a founding employee at Pixar Animation Studios, from 1986 to 1989 Hanrahan was part of the design of the RenderMan Interface Specification and the RenderMan Shading Language.\n",
      "He was credited in Pixar productions including The Magic Egg (1984), Tin Toy (1988) and Toy Story (1995).</p><p>In 1989 Hanrahan joined the faculty of Princeton University. In 1995 he moved to Stanford University. In 2003 Hanrahan co-founded Tableau Software and remains its chief scientist. In February 2005 Stanford University was named the first regional visualization and analytics center for the United States Department of Homeland Security, focused on problems in information visualization and visual analytics. In 2011 Intel Research announced funding for a center for visual computing, co-led by Hanrahan and Jim Hurley of Intel.</p><p>He was the doctoral advisor of Peter Schröder and Tamara Munzner.</p>\n",
      "<h2><span id=\"Awards\">Awards</span></h2>\n",
      "<p>Hanrahan received three Academy Awards for his work in rendering and computer graphics research. In 1993 Hanrahan and other Pixar founding employees were awarded a scientific and engineering award for RenderMan. In 2004 he shared a technical achievement award with Stephen R. Marschner and Henrik Wann Jensen, for research in simulating subsurface scattering of light in translucent materials.\n",
      "In 2014 he shared a technical achievement award with Matt Pharr and Greg Humphreys, for their formalization and reference implementation of the concepts behind physically based rendering, as shared in their book <i>Physically Based Rendering</i>.</p><p>Hanrahan received the 2003 SIGGRAPH Steven A. Coons Award for Outstanding Creative Contributions to Computer Graphics, for \"leadership in rendering algorithms, graphics architectures and systems, and new visualization methods for computer graphics\", and the 1993 SIGGRAPH Computer Graphics Achievement Award. He was inducted into the 2018 ACM SIGGRAPH Academy Inaugural Class.</p><p>He received the 2006 Career Award for Visualization Research from the IEEE Technical Committee on Visualization and Graphics (VGTC) at the IEEE Visualization Conference,</p><p>He became a member of the National Academy of Engineering in 1999, a Fellow of the American Academy of Arts and Sciences in 2007 and of the Association for Computing Machinery in 2008, and received three university teaching awards at Stanford.</p><p>Hanrahan shared the 2019 ACM A.M. Turing Award with Catmull for their pioneering efforts on computer-generated imagery.</p>\n",
      "<h2><span id=\"Quotes\">Quotes</span></h2>\n",
      "<ul><li><i><b>Curiosity and passion determine success</b></i></li></ul><h2><span id=\"References\">References</span></h2>\n",
      "<h2><span id=\"External_links\">External links</span></h2>\n",
      "<ul><li>Pat Hanrahan's academic home page</li>\n",
      "<li>Pat Hanrahan at DBLP Bibliography Server </li>\n",
      "<li>Pat Hanrahan author profile page at the ACM Digital Library </li>\n",
      "<li>Pat Hanrahan publications indexed by Google Scholar</li>\n",
      "<li>Pat Hanrahan at IMDb</li>\n",
      "<li><span>2019 AM Turing Award Recipients Ed Catmull and Pat Hanrahan Turing Lectures</span> on YouTube</li>\n",
      "<li><span>2013 Sci-Tech Awards: Matt Pharr, Greg Humphreys and Pat Hanrahan</span> on YouTube</li></ul>\n"
     ]
    }
   ],
   "source": [
    "def get_wikipedia_content(entity_id):\n",
    "    PARAMS_WBGETENTITIES_SITES[\"ids\"] = entity_id\n",
    "    wbgetentities_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_WBGETENTITIES_SITES)\n",
    "    wbgetentities_data = wbgetentities_response.json()\n",
    "    recipient_name = wbgetentities_data[\"entities\"][entity_id][\"sitelinks\"][\"enwiki\"][\"url\"].split(\"https://en.wikipedia.org/wiki/\")[1]\n",
    "\n",
    "    PARAMS_GETCONTENT[\"titles\"] = unquote(recipient_name)\n",
    "    extracts_response = requests.get(WIKIPEDIA_API_ENDPOINT, headers=HEADERS, params=PARAMS_GETCONTENT)\n",
    "    extracts_data = extracts_response.json()\n",
    "    html_content = next(iter(extracts_data[\"query\"][\"pages\"].values()))[\"extract\"]\n",
    "    content = BeautifulSoup(html_content, 'html.parser')\n",
    "    if content.find(\"p\", {\"class\":\"mw-empty-elt\"}):\n",
    "        content.find(\"p\", {\"class\":\"mw-empty-elt\"}).decompose()\n",
    "    return str(content)\n",
    "\n",
    "print(get_wikipedia_content(\"Q7143512\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_data_dict = {\"gender\": \"P21\", \"birth_date\": \"P569\", \"birth_city\": \"P19\", \n",
    "                  \"birth_country\": \"P17\", \"employer\": \"P108\", \"educated_at\": \"P69\"}\n",
    "\n",
    "def get_wikidata_claims(entity_id):\n",
    "    PARAMS_WBGETENTITIES_CLAIMS[\"ids\"] = entity_id\n",
    "    wbgetentities_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_WBGETENTITIES_CLAIMS)\n",
    "    wbgetentities_data = wbgetentities_response.json()\n",
    "    claims = next(iter(wbgetentities_data[\"entities\"].values()))[\"claims\"]\n",
    "    return claims\n",
    "\n",
    "def get_wikidata_label(entity_query):\n",
    "    PARAMS_WBGETENTITIES_LABELS[\"ids\"] = entity_query\n",
    "    request_ids = set(entity_query.split(\"|\"))\n",
    "    request_labels = dict()\n",
    "    wbgetentities_response = requests.get(WIKIDATA_API_ENDPOINT, headers=HEADERS, params=PARAMS_WBGETENTITIES_LABELS)\n",
    "    wbgetentities_data = wbgetentities_response.json()\n",
    "    for request_id in request_ids:\n",
    "        labels = wbgetentities_data[\"entities\"][request_id][\"labels\"]\n",
    "        request_labels[request_id] = labels[\"en\"][\"value\"]\n",
    "    return request_labels\n",
    "\n",
    "def check_key_exists(dict, key):\n",
    "    if key in dict.keys():\n",
    "        entity_ids = [dict[key][i][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"] for i in range(len(dict[key]))]\n",
    "        return entity_ids\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def call_wikidata_api(entity_id):\n",
    "    claims = get_wikidata_claims(entity_id)\n",
    "    request_entityids = {\"name_id\": [entity_id], \"gender_id\": check_key_exists(claims, wiki_data_dict[\"gender\"]),\n",
    "                       \"birth_city_id\" : check_key_exists(claims, wiki_data_dict[\"birth_city\"]),\n",
    "                       \"employers_ids\": check_key_exists(claims, wiki_data_dict[\"employer\"]),\n",
    "                       \"educated_at_ids\": check_key_exists(claims, wiki_data_dict[\"educated_at\"])}\n",
    "    \n",
    "    \n",
    "    entity_query = \"|\".join([\"|\".join(values) for values in request_entityids.values() if values != None])\n",
    "    request_labels = get_wikidata_label(entity_query)\n",
    "    \n",
    "    try:\n",
    "        name = request_labels[request_entityids[\"name_id\"][0]].split(\" (\")[0]\n",
    "    except TypeError:\n",
    "        name = None\n",
    "    try:\n",
    "        intro = get_wikipedia_content(entity_id).split(\"<h2>\")[0]\n",
    "    except TypeError:\n",
    "        intro = None   \n",
    "    try: \n",
    "        gender = request_labels[request_entityids[\"gender_id\"][0]]\n",
    "    except TypeError:\n",
    "        gender = None\n",
    "    try:\n",
    "        birth_date = datetime.strptime(claims[wiki_data_dict[\"birth_date\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"time\"], \"+%Y-%m-%dT%XZ\").strftime(\"%d %B %Y\")\n",
    "    except ValueError:\n",
    "        birth_date = datetime.strptime(claims[wiki_data_dict[\"birth_date\"]][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"time\"], \"+%Y-00-00T%XZ\").strftime(\"%Y\")\n",
    "    except TypeError:\n",
    "        birth_date = None\n",
    "    try:\n",
    "        birth_place = request_labels[request_entityids[\"birth_city_id\"][0]] \n",
    "    except TypeError:\n",
    "        birth_place = None\n",
    "    if request_entityids[\"employers_ids\"] != None:\n",
    "        employer = [request_labels[key] for key in request_entityids[\"employers_ids\"]]\n",
    "    else:\n",
    "        employer = None\n",
    "    if request_entityids[\"employers_ids\"] != None:\n",
    "        education = [request_labels[key] for key in request_entityids[\"educated_at_ids\"]]\n",
    "    else:\n",
    "        education = None\n",
    "    return name, intro, gender, birth_date, birth_place, employer, education\n",
    "\n",
    "def multi_thread_api_call(entity_ids, workers=10):\n",
    "    results = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "        api_calls = {executor.submit(call_wikidata_api, entity_id): entity_id for entity_id in entity_ids}\n",
    "        while api_calls:\n",
    "            retry_api_calls = {}\n",
    "            done, pending = wait(api_calls, return_when=FIRST_COMPLETED)\n",
    "            for api_call in done:\n",
    "                if api_call.exception():\n",
    "                    entity_id = api_calls[api_call]\n",
    "                    retry_api_calls[executor.submit(call_wikidata_api, entity_id)] = entity_id\n",
    "                else:\n",
    "                    results.append(api_call.result())\n",
    "            for api_call in pending:\n",
    "                entity_id = api_calls[api_call]\n",
    "                retry_api_calls[api_call] = entity_id\n",
    "            api_calls = retry_api_calls    \n",
    "    return results\n",
    "\n",
    "def get_award_winners_data(results, award_winners_dict):\n",
    "    for result in results:\n",
    "        name, intro, gender, birth_date, birth_place, employer, education = result\n",
    "        award_winners_dict[\"name\"].append(name)\n",
    "        award_winners_dict[\"intro\"].append(intro)\n",
    "        award_winners_dict[\"gender\"].append(gender)\n",
    "        award_winners_dict[\"birth_date\"].append(birth_date)\n",
    "        award_winners_dict[\"birth_place\"].append(birth_place)\n",
    "        award_winners_dict[\"employer\"].append(employer)\n",
    "        award_winners_dict[\"educated_at\"].append(education)\n",
    "    return award_winners_dict\n",
    "\n",
    "award_winners_dict = {\"name\": [], \"intro\": [], \"gender\": [], \"birth_date\": [], \n",
    "                      \"birth_place\": [], \"employer\": [], \"educated_at\": []} \n",
    "acm_award_winners = get_turing_award_recipients()\n",
    "api_calls = multi_thread_api_call(acm_award_winners, 15)\n",
    " \n",
    "award_winners = get_award_winners_data(api_calls, award_winners_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adi Shamir\n",
      "Alan Kay\n",
      "Alan Perlis\n",
      "Alfred Aho\n",
      "Allen Newell\n",
      "Amir Pnueli\n",
      "Andrew Yao\n",
      "Barbara Liskov\n",
      "Bob Kahn\n",
      "Butler Lampson\n",
      "Charles Bachman\n",
      "Charles P. Thacker\n",
      "Dana Scott\n",
      "David A. Patterson\n",
      "Dennis M. Ritchie\n",
      "Donald Knuth\n",
      "Douglas Engelbart\n",
      "E. Allen Emerson\n",
      "Edgar F. Codd\n",
      "Edmund M. Clarke\n",
      "Edsger W. Dijkstra\n",
      "Edward Feigenbaum\n",
      "Edwin Catmull\n",
      "Fernando J. Corbató\n",
      "Frances E. Allen\n",
      "Fred Brooks\n",
      "Geoffrey Hinton\n",
      "Herbert Simon\n",
      "Iosif Sifakis\n",
      "Ivan Sutherland\n",
      "Jack Dongarra\n",
      "James H. Wilkinson\n",
      "Jeffrey David Ullman\n",
      "Jim Gray\n",
      "John Backus\n",
      "John Cocke\n",
      "John Edward Hopcroft\n",
      "John L. Hennessy\n",
      "John McCarthy\n",
      "Judea Pearl\n",
      "Juris Hartmanis\n",
      "Ken Thompson\n",
      "Kenneth E. Iverson\n",
      "Kristen Nygaard\n",
      "Leonard Adleman\n",
      "Leslie Lamport\n",
      "Leslie Valiant\n",
      "Manuel Blum\n",
      "Martin Edward Hellman\n",
      "Marvin Minsky\n",
      "Maurice Wilkes\n",
      "Michael O. Rabin\n",
      "Michael Stonebraker\n",
      "Niklaus Wirth\n",
      "Ole-Johan Dahl\n",
      "Pat Hanrahan\n",
      "Peter Naur\n",
      "Raj Reddy\n",
      "Richard E. Stearns\n",
      "Richard Hamming\n",
      "Richard M. Karp\n",
      "Robert Tarjan\n",
      "Robert W. Floyd\n",
      "Robin Milner\n",
      "Ron Rivest\n",
      "Shafrira Goldwasser\n",
      "Silvio Micali\n",
      "Stephen Cook\n",
      "Tim Berners-Lee\n",
      "Tony Hoare\n",
      "Vint Cerf\n",
      "Whitfield Diffie\n",
      "William Kahan\n",
      "Yann LeCun\n",
      "Yoshua Bengio\n"
     ]
    }
   ],
   "source": [
    "for name in sorted(award_winners[\"name\"]):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_name</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_sentences</th>\n",
       "      <th>count_paragraphs</th>\n",
       "      <th>common_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ron Rivest</td>\n",
       "      <td>123</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, of, the, is, Rivest, a, MIT, He, 's, at]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, the, of, Bengio, for, is, a, work, deep,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geoffrey Hinton</td>\n",
       "      <td>176</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, and, of, for, in, Hinton, a, his, to, is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Judea Pearl</td>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, and, for, of, Pearl, is, on, a, in, Judea]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Herbert Simon</td>\n",
       "      <td>175</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, and, was, in, science, to, political...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Richard M. Karp</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[in, and, the, of, for, Karp, is, computer, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vint Cerf</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, of, and, is, Internet, National, Medal, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dana Scott</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, is, of, and, in, University, work, on, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jeffrey David Ullman</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, as, and, of, are, computer, Stanford, kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Robert Tarjan</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[and, Tarjan, is, the, of, University, at, Rob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>John McCarthy</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, and, He, McCarthy, was, scientist, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Marvin Minsky</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, of, AI, Minsky, the, Marvin, Lee, August...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Donald Knuth</td>\n",
       "      <td>182</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, of, and, Knuth, computer, is, to, He, sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tony Hoare</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, as, and, of, are, computer, Stanford, kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tim Berners-Lee</td>\n",
       "      <td>348</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>[the, of, and, Web, He, a, is, as, World, Wide]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Michael Stonebraker</td>\n",
       "      <td>162</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, Stonebraker, of, as, is, database, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manuel Blum</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, of, to, and, Manuel, Blum, born, 26, Apr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Shafrira Goldwasser</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[of, the, and, at, is, scientist, Science, Ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Yann LeCun</td>\n",
       "      <td>157</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>[of, the, and, is, He, computer, with, LeCun, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Stephen Cook</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[of, and, is, the, complexity, Department, Ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Niklaus Wirth</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[computer, a, several, languages, in, the, Nik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Barbara Liskov</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, in, is, and, Liskov, computer, Barba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Leslie Lamport</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, and, of, in, systems, Lamport, distribut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Edmund M. Clarke</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[and, Clarke, was, for, the, Edmund, Melson, J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Michael O. Rabin</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[and, Michael, Oser, Rabin, Hebrew, מִיכָאֵל, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Allen Newell</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, and, of, 19, was, in, psychology, at, Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Fred Brooks</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, of, computer, and, in, Brooks, was, soft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Jack Dongarra</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, of, University, at, is, and, Computer, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Edsger W. Dijkstra</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, was, of, his, in, Dijkstra, Dutch, 2002,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>John Edward Hopcroft</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[of, the, and, at, University, John, Hopcroft,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Pat Hanrahan</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, graphics, Computer, and, as, Patrick, M....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Ken Thompson</td>\n",
       "      <td>129</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, and, of, his, Thompson, computer, progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dennis M. Ritchie</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, and, in, Ritchie, was, from, He, C, prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>John L. Hennessy</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[of, the, as, Hennessy, is, computer, in, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Adi Shamir</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[of, the, and, is, a, co-inventor, along, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Alan Perlis</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[and, University, was, the, Alan, Jay, Perlis,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>David A. Patterson</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>[of, the, computer, RISC, is, and, Patterson, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Silvio Micali</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, Micali, of, and, cryptography, Silvio, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Juris Hartmanis</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, July, computational, of, Juris, Hartmani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Douglas Engelbart</td>\n",
       "      <td>281</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, of, and, in, Engelbart, was, his, at, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Andrew Yao</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[Yao, and, the, Chinese, is, a, of, for, Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Amir Pnueli</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Amir, Pnueli, Hebrew, אמיר, פנואלי, April, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Martin Edward Hellman</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[and, to, the, Hellman, a, of, for, with, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Alfred Aho</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, and, his, of, computer, programming, Aho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Robert W. Floyd</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, a, of, in, Floyd, was, to, algorithm, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Alan Kay</td>\n",
       "      <td>123</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, and, is, object-oriented, also, He, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Robin Milner</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Milner, Robin, a, Arthur, John, Gorell, 13, J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Edward Feigenbaum</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, of, is, Edward, Albert, Feigenbaum, born...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bob Kahn</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, Kahn, with, Vint, Cerf, Protocol, Intern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Ivan Sutherland</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, of, in, computer, as, graphics, and, tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Leslie Valiant</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[and, a, in, the, of, Valiant, born, is, compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Edgar F. Codd</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[relational, for, the, management, computer, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Peter Naur</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, a, He, to, Peter, Naur, 25, October, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Kenneth E. Iverson</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, for, of, programming, APL, in, and, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>John Backus</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, and, of, in, He, programming, his, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Richard E. Stearns</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, in, a, Stearns, is, University, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Leonard Adleman</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, of, is, He, for, Leonard, Adleman, born,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Maurice Wilkes</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, of, a, Wilkes, was, who, and, unit, Sir,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>E. Allen Emerson</td>\n",
       "      <td>123</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, of, the, is, Emerson, model, checking, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>William Kahan</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[in, and, the, William, Velvel, Morton, Kahan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Whitfield Diffie</td>\n",
       "      <td>148</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, a, of, the, at, for, Diffie, key, as, is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>James H. Wilkinson</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, the, field, of, and, James, Hardy, Wilkins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Iosif Sifakis</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[Joseph, Sifakis, Greek, Ιωσήφ, Σηφάκης, is, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>John Cocke</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[computer, to, architecture, John, Cocke, May,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Kristen Nygaard</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, Nygaard, programming, and, August, compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Richard Hamming</td>\n",
       "      <td>217</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, Hamming, in, he, and, of, a, University,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Fernando J. Corbató</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[July, a, Fernando, José, Corby, Corbató, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Edwin Catmull</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, is, computer, of, Edwin, Earl, Ed, Catmu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Charles Bachman</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[his, Bachman, was, an, in, of, Charles, Willi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Frances E. Allen</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[and, the, was, in, to, Allen, August, 4, an, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Jim Gray</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[in, and, James, Nicholas, Gray, 1944, declare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Butler Lampson</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Butler, W., Lampson, ForMemRS, born, December...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Raj Reddy</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[of, the, He, is, in, to, and, Turing, Award, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Charles P. Thacker</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[computer, the, Charles, Patrick, Chuck, Thack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Ole-Johan Dahl</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[of, Dahl, was, a, computer, the, and, Ole-Joh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              winner_name  count_words  count_sentences  count_paragraphs  \\\n",
       "0              Ron Rivest          123                8                 2   \n",
       "1           Yoshua Bengio           90                4                 2   \n",
       "2         Geoffrey Hinton          176                8                 3   \n",
       "3             Judea Pearl          154                5                 2   \n",
       "4           Herbert Simon          175                7                 2   \n",
       "5         Richard M. Karp           91                3                 2   \n",
       "6               Vint Cerf           62                2                 1   \n",
       "7              Dana Scott           83                3                 1   \n",
       "8    Jeffrey David Ullman           80                3                 1   \n",
       "9           Robert Tarjan           59                3                 1   \n",
       "10          John McCarthy           97                5                 2   \n",
       "11          Marvin Minsky           51                2                 2   \n",
       "12           Donald Knuth          182                8                 3   \n",
       "13             Tony Hoare           80                3                 1   \n",
       "14        Tim Berners-Lee          348               17                 4   \n",
       "15    Michael Stonebraker          162                7                 2   \n",
       "16            Manuel Blum           37                1                 1   \n",
       "17    Shafrira Goldwasser           68                2                 1   \n",
       "18             Yann LeCun          157                7                 3   \n",
       "19           Stephen Cook           45                2                 1   \n",
       "20          Niklaus Wirth           52                3                 1   \n",
       "21         Barbara Liskov          108                5                 2   \n",
       "22         Leslie Lamport          111                5                 1   \n",
       "23       Edmund M. Clarke           59                3                 1   \n",
       "24       Michael O. Rabin           23                1                 1   \n",
       "25           Allen Newell           93                3                 1   \n",
       "26            Fred Brooks           95                3                 3   \n",
       "27          Jack Dongarra          113                5                 1   \n",
       "28     Edsger W. Dijkstra          100                4                 2   \n",
       "29   John Edward Hopcroft           78                3                 1   \n",
       "30           Pat Hanrahan           55                3                 1   \n",
       "31           Ken Thompson          129                6                 2   \n",
       "32      Dennis M. Ritchie           99                5                 1   \n",
       "33       John L. Hennessy          109                5                 2   \n",
       "34             Adi Shamir           59                2                 1   \n",
       "35            Alan Perlis           45                2                 1   \n",
       "36     David A. Patterson          160                8                 3   \n",
       "37          Silvio Micali           42                3                 2   \n",
       "38        Juris Hartmanis           44                1                 1   \n",
       "39      Douglas Engelbart          281               10                 3   \n",
       "40             Andrew Yao           81                5                 2   \n",
       "41            Amir Pnueli           22                1                 1   \n",
       "42  Martin Edward Hellman          111                4                 3   \n",
       "43             Alfred Aho           80                3                 3   \n",
       "44        Robert W. Floyd          112                6                 1   \n",
       "45               Alan Kay          123                7                 2   \n",
       "46           Robin Milner           31                1                 1   \n",
       "47      Edward Feigenbaum           36                2                 1   \n",
       "48               Bob Kahn           53                2                 2   \n",
       "49        Ivan Sutherland          150                6                 1   \n",
       "50         Leslie Valiant           95                5                 1   \n",
       "51          Edgar F. Codd           66                2                 1   \n",
       "52             Peter Naur           51                3                 1   \n",
       "53     Kenneth E. Iverson           73                2                 1   \n",
       "54            John Backus          150                6                 3   \n",
       "55     Richard E. Stearns          119                6                 2   \n",
       "56        Leonard Adleman           51                3                 1   \n",
       "57         Maurice Wilkes           69                2                 1   \n",
       "58       E. Allen Emerson          123                5                 2   \n",
       "59          William Kahan           46                1                 1   \n",
       "60       Whitfield Diffie          148                6                 2   \n",
       "61     James H. Wilkinson           37                1                 1   \n",
       "62          Iosif Sifakis           30                2                 1   \n",
       "63             John Cocke           37                2                 1   \n",
       "64        Kristen Nygaard           52                3                 1   \n",
       "65        Richard Hamming          217                9                 3   \n",
       "66    Fernando J. Corbató           26                1                 1   \n",
       "67          Edwin Catmull           44                2                 1   \n",
       "68        Charles Bachman           56                3                 1   \n",
       "69       Frances E. Allen           69                4                 1   \n",
       "70               Jim Gray           36                1                 1   \n",
       "71         Butler Lampson           27                1                 1   \n",
       "72              Raj Reddy          126                6                 1   \n",
       "73     Charles P. Thacker           33                2                 1   \n",
       "74         Ole-Johan Dahl           41                2                 1   \n",
       "\n",
       "                                         common_words  \n",
       "0      [and, of, the, is, Rivest, a, MIT, He, 's, at]  \n",
       "1   [and, the, of, Bengio, for, is, a, work, deep,...  \n",
       "2     [the, and, of, for, in, Hinton, a, his, to, is]  \n",
       "3    [the, and, for, of, Pearl, is, on, a, in, Judea]  \n",
       "4   [the, of, and, was, in, science, to, political...  \n",
       "5   [in, and, the, of, for, Karp, is, computer, th...  \n",
       "6   [the, of, and, is, Internet, National, Medal, ...  \n",
       "7   [the, is, of, and, in, University, work, on, t...  \n",
       "8   [the, as, and, of, are, computer, Stanford, kn...  \n",
       "9   [and, Tarjan, is, the, of, University, at, Rob...  \n",
       "10  [the, of, and, He, McCarthy, was, scientist, a...  \n",
       "11  [and, of, AI, Minsky, the, Marvin, Lee, August...  \n",
       "12  [the, of, and, Knuth, computer, is, to, He, sc...  \n",
       "13  [the, as, and, of, are, computer, Stanford, kn...  \n",
       "14    [the, of, and, Web, He, a, is, as, World, Wide]  \n",
       "15  [and, Stonebraker, of, as, is, database, the, ...  \n",
       "16  [the, of, to, and, Manuel, Blum, born, 26, Apr...  \n",
       "17  [of, the, and, at, is, scientist, Science, Ins...  \n",
       "18  [of, the, and, is, He, computer, with, LeCun, ...  \n",
       "19  [of, and, is, the, complexity, Department, Ste...  \n",
       "20  [computer, a, several, languages, in, the, Nik...  \n",
       "21  [the, of, in, is, and, Liskov, computer, Barba...  \n",
       "22  [the, and, of, in, systems, Lamport, distribut...  \n",
       "23  [and, Clarke, was, for, the, Edmund, Melson, J...  \n",
       "24  [and, Michael, Oser, Rabin, Hebrew, מִיכָאֵל, ...  \n",
       "25  [the, and, of, 19, was, in, psychology, at, Sc...  \n",
       "26  [the, of, computer, and, in, Brooks, was, soft...  \n",
       "27  [the, of, University, at, is, and, Computer, S...  \n",
       "28  [the, was, of, his, in, Dijkstra, Dutch, 2002,...  \n",
       "29  [of, the, and, at, University, John, Hopcroft,...  \n",
       "30  [the, graphics, Computer, and, as, Patrick, M....  \n",
       "31  [the, and, of, his, Thompson, computer, progra...  \n",
       "32  [the, and, in, Ritchie, was, from, He, C, prog...  \n",
       "33  [of, the, as, Hennessy, is, computer, in, and,...  \n",
       "34  [of, the, and, is, a, co-inventor, along, with...  \n",
       "35  [and, University, was, the, Alan, Jay, Perlis,...  \n",
       "36  [of, the, computer, RISC, is, and, Patterson, ...  \n",
       "37  [the, Micali, of, and, cryptography, Silvio, b...  \n",
       "38  [the, July, computational, of, Juris, Hartmani...  \n",
       "39  [the, of, and, in, Engelbart, was, his, at, to...  \n",
       "40  [Yao, and, the, Chinese, is, a, of, for, Scien...  \n",
       "41  [Amir, Pnueli, Hebrew, אמיר, פנואלי, April, 22...  \n",
       "42  [and, to, the, Hellman, a, of, for, with, is, ...  \n",
       "43  [the, and, his, of, computer, programming, Aho...  \n",
       "44  [the, a, of, in, Floyd, was, to, algorithm, fo...  \n",
       "45  [the, of, and, is, object-oriented, also, He, ...  \n",
       "46  [Milner, Robin, a, Arthur, John, Gorell, 13, J...  \n",
       "47  [the, of, is, Edward, Albert, Feigenbaum, born...  \n",
       "48  [the, Kahn, with, Vint, Cerf, Protocol, Intern...  \n",
       "49  [the, of, in, computer, as, graphics, and, tha...  \n",
       "50  [and, a, in, the, of, Valiant, born, is, compu...  \n",
       "51  [relational, for, the, management, computer, m...  \n",
       "52  [the, a, He, to, Peter, Naur, 25, October, 192...  \n",
       "53  [the, for, of, programming, APL, in, and, to, ...  \n",
       "54  [the, and, of, in, He, programming, his, for, ...  \n",
       "55  [the, of, in, a, Stearns, is, University, with...  \n",
       "56  [the, of, is, He, for, Leonard, Adleman, born,...  \n",
       "57  [the, of, a, Wilkes, was, who, and, unit, Sir,...  \n",
       "58  [and, of, the, is, Emerson, model, checking, i...  \n",
       "59  [in, and, the, William, Velvel, Morton, Kahan,...  \n",
       "60    [and, a, of, the, at, for, Diffie, key, as, is]  \n",
       "61  [a, the, field, of, and, James, Hardy, Wilkins...  \n",
       "62  [Joseph, Sifakis, Greek, Ιωσήφ, Σηφάκης, is, a...  \n",
       "63  [computer, to, architecture, John, Cocke, May,...  \n",
       "64  [the, Nygaard, programming, and, August, compu...  \n",
       "65  [the, Hamming, in, he, and, of, a, University,...  \n",
       "66  [July, a, Fernando, José, Corby, Corbató, 1, 1...  \n",
       "67  [the, is, computer, of, Edwin, Earl, Ed, Catmu...  \n",
       "68  [his, Bachman, was, an, in, of, Charles, Willi...  \n",
       "69  [and, the, was, in, to, Allen, August, 4, an, ...  \n",
       "70  [in, and, James, Nicholas, Gray, 1944, declare...  \n",
       "71  [Butler, W., Lampson, ForMemRS, born, December...  \n",
       "72  [of, the, He, is, in, to, and, Turing, Award, ...  \n",
       "73  [computer, the, Charles, Patrick, Chuck, Thack...  \n",
       "74  [of, Dahl, was, a, computer, the, and, Ole-Joh...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award_winners_intro = pd.DataFrame(columns=[\"winner_name\", \"count_words\", \"count_sentences\", \"count_paragraphs\", \"common_words\"])\n",
    "award_winners_intro[\"winner_name\"] = award_winners[\"name\"]\n",
    "\n",
    "def get_intro_stats(intro): \n",
    "    intro_html = BeautifulSoup(intro, \"html.parser\")\n",
    "    intro_text = intro_html.get_text(\" \")\n",
    "    count_words = sum([word.strip(string.punctuation).isalnum() for word in intro_text.split()])\n",
    "    count_sentences = len(sent_tokenize(intro_text))\n",
    "    count_paragraphs = len(intro_html.find_all(\"p\"))\n",
    "    word_filter = set(list(string.punctuation) + [\"``\", \"''\", \"–\"])\n",
    "    word_freqdist= nltk.FreqDist([word for word in word_tokenize(intro_text) if word not in word_filter]).most_common(10)\n",
    "    common_words = [word[0] for word in word_freqdist]\n",
    "    return count_words, count_sentences, count_paragraphs, common_words\n",
    "\n",
    "intro_stats = {\"word_count\": [], \"sentence_count\": [], \"paragraph_count\": [], \"common_words\": []}\n",
    "for intro in award_winners[\"intro\"]:\n",
    "    count_word, count_sentences, count_paragraphs, common_words = get_intro_stats(intro)\n",
    "    intro_stats[\"word_count\"].append(count_word)\n",
    "    intro_stats[\"sentence_count\"].append(count_sentences)\n",
    "    intro_stats[\"paragraph_count\"].append(count_paragraphs)\n",
    "    intro_stats[\"common_words\"].append(common_words)\n",
    "\n",
    "award_winners_intro[\"count_words\"] = intro_stats[\"word_count\"]\n",
    "award_winners_intro[\"count_sentences\"] = intro_stats[\"sentence_count\"]\n",
    "award_winners_intro[\"count_paragraphs\"] = intro_stats[\"paragraph_count\"]\n",
    "award_winners_intro[\"common_words\"] = intro_stats[\"common_words\"]\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "award_winners_intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            winner_name  count_words  count_sentences  count_paragraphs  \\\n",
      "0            Ron Rivest          123                8                 2   \n",
      "1         Yoshua Bengio           90                4                 2   \n",
      "2       Geoffrey Hinton          176                8                 3   \n",
      "3           Judea Pearl          154                5                 2   \n",
      "4         Herbert Simon          175                7                 2   \n",
      "5       Richard M. Karp           91                3                 2   \n",
      "6             Vint Cerf           62                2                 1   \n",
      "7            Dana Scott           83                3                 1   \n",
      "8  Jeffrey David Ullman           80                3                 1   \n",
      "9         Robert Tarjan           59                3                 1   \n",
      "\n",
      "                                        common_words  \\\n",
      "0     [and, of, the, is, Rivest, a, MIT, He, 's, at]   \n",
      "1  [and, the, of, Bengio, for, is, a, work, deep,...   \n",
      "2    [the, and, of, for, in, Hinton, a, his, to, is]   \n",
      "3   [the, and, for, of, Pearl, is, on, a, in, Judea]   \n",
      "4  [the, of, and, was, in, science, to, political...   \n",
      "5  [in, and, the, of, for, Karp, is, computer, th...   \n",
      "6  [the, of, and, is, Internet, National, Medal, ...   \n",
      "7  [the, is, of, and, in, University, work, on, t...   \n",
      "8  [the, as, and, of, are, computer, Stanford, kn...   \n",
      "9  [and, Tarjan, is, the, of, University, at, Rob...   \n",
      "\n",
      "                    common_words_after_preprocessing  \n",
      "0  [Rivest, MIT, He, 's, member, Computer, Scienc...  \n",
      "1  [Bengio, work, deep, learning, Learning, Hinto...  \n",
      "2  [Hinton, computer, work, neural, networks, Goo...  \n",
      "3  [Pearl, Judea, computer, probabilistic, artifi...  \n",
      "4  [science, political, computer, He, Simon, 2001...  \n",
      "5  [Karp, computer, theory, algorithms, Richard, ...  \n",
      "6  [Internet, National, Medal, Vinton, Gray, Cerf...  \n",
      "7  [University, work, theory, Dana, Stewart, Scot...  \n",
      "8  [computer, Stanford, known, book, Jeffrey, Dav...  \n",
      "9  [Tarjan, University, Robert, Endre, born, Apri...  \n"
     ]
    }
   ],
   "source": [
    "def process_common_words(intro):\n",
    "    intro_text = BeautifulSoup(intro, \"html.parser\").get_text(\" \")\n",
    "    word_filter = set(stopwords.words('english') + list(string.punctuation) + [\"``\", \"''\", \"–\"])\n",
    "    tokenized_intro = word_tokenize(intro_text)\n",
    "    word_freqdist = nltk.FreqDist([word for word in tokenized_intro if word not in word_filter]).most_common(10)\n",
    "    common_words = [word[0] for word in word_freqdist]\n",
    "    return common_words\n",
    "\n",
    "common_words_after_preprocessing = [process_common_words(intro) for intro in award_winners[\"intro\"]]\n",
    "award_winners_intro[\"common_words_after_preprocessing\"] = common_words_after_preprocessing\n",
    "\n",
    "print(award_winners_intro.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Sub Activity\n",
    "\n",
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words before stemming with Porter Stemmer: 1742\n",
      "Number of unique words after stemming with Porter Stemmer: 1448\n"
     ]
    }
   ],
   "source": [
    "long_intro_text = \" \".join([BeautifulSoup(intro, \"html.parser\").get_text(\" \") for intro in award_winners[\"intro\"]])\n",
    "\n",
    "word_filter = set(stopwords.words('english') + list(string.punctuation) + [\"``\", \"''\", \"–\"])\n",
    "tokenized_intro = word_tokenize(long_intro_text)\n",
    "intro_words = [word for word in tokenized_intro if word not in word_filter]\n",
    "\n",
    "print(\"Number of unique words before stemming with Porter Stemmer: {}\".format(len(list(nltk.FreqDist(intro_words)))))\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "intro_words = [porter_stemmer.stem(word) for word in intro_words]\n",
    "\n",
    "print(\"Number of unique words after stemming with Porter Stemmer: {}\".format(len(list(nltk.FreqDist(intro_words)))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words before stemming with Snowball Stemmer: 1742\n",
      "Number of unique words after stemming with Snowball Stemmer: 1446\n"
     ]
    }
   ],
   "source": [
    "long_intro_text = \" \".join([BeautifulSoup(intro, \"html.parser\").get_text(\" \") for intro in award_winners[\"intro\"]])\n",
    "\n",
    "word_filter = set(stopwords.words('english') + list(string.punctuation) + [\"``\", \"''\", \"–\"])\n",
    "tokenized_intro = word_tokenize(long_intro_text)\n",
    "intro_words = [word for word in tokenized_intro if word not in word_filter]\n",
    "\n",
    "print(\"Number of unique words before stemming with Snowball Stemmer: {}\".format(len(list(nltk.FreqDist(intro_words)))))\n",
    "\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "intro_words = [snow_stemmer.stem(word) for word in intro_words]\n",
    "\n",
    "print(\"Number of unique words after stemming with Snowball Stemmer: {}\".format(len(list(nltk.FreqDist(intro_words)))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words before lemmatization with Word Net Lemmatizer: 1742\n",
      "Number of unique words after lemmatization with Word Net Lemmatizer: 1695\n"
     ]
    }
   ],
   "source": [
    "long_intro_text = \" \".join([BeautifulSoup(intro, \"html.parser\").get_text(\" \") for intro in award_winners[\"intro\"]])\n",
    "\n",
    "word_filter = set(stopwords.words('english') + list(string.punctuation) + [\"``\", \"''\", \"–\"])\n",
    "tokenized_intro = word_tokenize(long_intro_text)\n",
    "intro_words = [word for word in tokenized_intro if word not in word_filter]\n",
    "\n",
    "print(\"Number of unique words before lemmatization with Word Net Lemmatizer: {}\".format(len(list(nltk.FreqDist(intro_words)))))\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "intro_words = [wordnet_lemmatizer.lemmatize(word) for word in intro_words]\n",
    "\n",
    "print(\"Number of unique words after lemmatization with Word Net Lemmatizer: {}\".format(len(list(nltk.FreqDist(intro_words)))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_490/2519469690.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  award_winners_intro[\"synonyms\"][i] = list(OrderedDict.fromkeys(synonyms))\n",
      "/tmp/ipykernel_490/2519469690.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  award_winners_intro[\"antonyms\"][i] = list(OrderedDict.fromkeys(antonyms))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_name</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_sentences</th>\n",
       "      <th>count_paragraphs</th>\n",
       "      <th>common_words</th>\n",
       "      <th>common_words_after_preprocessing</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>antonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ron Rivest</td>\n",
       "      <td>123</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, of, the, is, Rivest, a, MIT, He, 's, at]</td>\n",
       "      <td>[Rivest, MIT, He, 's, member, Computer, Scienc...</td>\n",
       "      <td>[Massachusetts_Institute_of_Technology, helium...</td>\n",
       "      <td>[nonmember]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, the, of, Bengio, for, is, a, work, deep,...</td>\n",
       "      <td>[Bengio, work, deep, learning, Learning, Hinto...</td>\n",
       "      <td>[piece_of_work, employment, study, workplace, ...</td>\n",
       "      <td>[idle, malfunction, shallow, unborn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geoffrey Hinton</td>\n",
       "      <td>176</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>[the, and, of, for, in, Hinton, a, his, to, is]</td>\n",
       "      <td>[Hinton, computer, work, neural, networks, Goo...</td>\n",
       "      <td>[computing_machine, computing_device, data_pro...</td>\n",
       "      <td>[idle, malfunction, shallow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Judea Pearl</td>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, and, for, of, Pearl, is, on, a, in, Judea]</td>\n",
       "      <td>[Pearl, Judea, computer, probabilistic, artifi...</td>\n",
       "      <td>[pearl, bone, ivory, off-white, drop, bead, Ju...</td>\n",
       "      <td>[natural, stupidity, devolution, nondevelopment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Herbert Simon</td>\n",
       "      <td>175</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, of, and, was, in, science, to, political...</td>\n",
       "      <td>[science, political, computer, He, Simon, 2001...</td>\n",
       "      <td>[scientific_discipline, skill, computing_machi...</td>\n",
       "      <td>[nonpolitical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Richard M. Karp</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[in, and, the, of, for, Karp, is, computer, th...</td>\n",
       "      <td>[Karp, computer, theory, algorithms, Richard, ...</td>\n",
       "      <td>[computing_machine, computing_device, data_pro...</td>\n",
       "      <td>[unborn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vint Cerf</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, of, and, is, Internet, National, Medal, ...</td>\n",
       "      <td>[Internet, National, Medal, Vinton, Gray, Cerf...</td>\n",
       "      <td>[internet, net, cyberspace, national, subject,...</td>\n",
       "      <td>[international, local, unborn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dana Scott</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, is, of, and, in, University, work, on, t...</td>\n",
       "      <td>[University, work, theory, Dana, Stewart, Scot...</td>\n",
       "      <td>[university, piece_of_work, employment, study,...</td>\n",
       "      <td>[idle, malfunction, unborn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jeffrey David Ullman</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, as, and, of, are, computer, Stanford, kn...</td>\n",
       "      <td>[computer, Stanford, known, book, Jeffrey, Dav...</td>\n",
       "      <td>[computing_machine, computing_device, data_pro...</td>\n",
       "      <td>[ignore, unknown, unborn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Robert Tarjan</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[and, Tarjan, is, the, of, University, at, Rob...</td>\n",
       "      <td>[Tarjan, University, Robert, Endre, born, Apri...</td>\n",
       "      <td>[university, Henry_M._Robert, Henry_Martyn_Rob...</td>\n",
       "      <td>[unborn]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            winner_name  count_words  count_sentences  count_paragraphs  \\\n",
       "0            Ron Rivest          123                8                 2   \n",
       "1         Yoshua Bengio           90                4                 2   \n",
       "2       Geoffrey Hinton          176                8                 3   \n",
       "3           Judea Pearl          154                5                 2   \n",
       "4         Herbert Simon          175                7                 2   \n",
       "5       Richard M. Karp           91                3                 2   \n",
       "6             Vint Cerf           62                2                 1   \n",
       "7            Dana Scott           83                3                 1   \n",
       "8  Jeffrey David Ullman           80                3                 1   \n",
       "9         Robert Tarjan           59                3                 1   \n",
       "\n",
       "                                        common_words  \\\n",
       "0     [and, of, the, is, Rivest, a, MIT, He, 's, at]   \n",
       "1  [and, the, of, Bengio, for, is, a, work, deep,...   \n",
       "2    [the, and, of, for, in, Hinton, a, his, to, is]   \n",
       "3   [the, and, for, of, Pearl, is, on, a, in, Judea]   \n",
       "4  [the, of, and, was, in, science, to, political...   \n",
       "5  [in, and, the, of, for, Karp, is, computer, th...   \n",
       "6  [the, of, and, is, Internet, National, Medal, ...   \n",
       "7  [the, is, of, and, in, University, work, on, t...   \n",
       "8  [the, as, and, of, are, computer, Stanford, kn...   \n",
       "9  [and, Tarjan, is, the, of, University, at, Rob...   \n",
       "\n",
       "                    common_words_after_preprocessing  \\\n",
       "0  [Rivest, MIT, He, 's, member, Computer, Scienc...   \n",
       "1  [Bengio, work, deep, learning, Learning, Hinto...   \n",
       "2  [Hinton, computer, work, neural, networks, Goo...   \n",
       "3  [Pearl, Judea, computer, probabilistic, artifi...   \n",
       "4  [science, political, computer, He, Simon, 2001...   \n",
       "5  [Karp, computer, theory, algorithms, Richard, ...   \n",
       "6  [Internet, National, Medal, Vinton, Gray, Cerf...   \n",
       "7  [University, work, theory, Dana, Stewart, Scot...   \n",
       "8  [computer, Stanford, known, book, Jeffrey, Dav...   \n",
       "9  [Tarjan, University, Robert, Endre, born, Apri...   \n",
       "\n",
       "                                            synonyms  \\\n",
       "0  [Massachusetts_Institute_of_Technology, helium...   \n",
       "1  [piece_of_work, employment, study, workplace, ...   \n",
       "2  [computing_machine, computing_device, data_pro...   \n",
       "3  [pearl, bone, ivory, off-white, drop, bead, Ju...   \n",
       "4  [scientific_discipline, skill, computing_machi...   \n",
       "5  [computing_machine, computing_device, data_pro...   \n",
       "6  [internet, net, cyberspace, national, subject,...   \n",
       "7  [university, piece_of_work, employment, study,...   \n",
       "8  [computing_machine, computing_device, data_pro...   \n",
       "9  [university, Henry_M._Robert, Henry_Martyn_Rob...   \n",
       "\n",
       "                                           antonyms  \n",
       "0                                       [nonmember]  \n",
       "1              [idle, malfunction, shallow, unborn]  \n",
       "2                      [idle, malfunction, shallow]  \n",
       "3  [natural, stupidity, devolution, nondevelopment]  \n",
       "4                                    [nonpolitical]  \n",
       "5                                          [unborn]  \n",
       "6                    [international, local, unborn]  \n",
       "7                       [idle, malfunction, unborn]  \n",
       "8                         [ignore, unknown, unborn]  \n",
       "9                                          [unborn]  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award_winners_intro = award_winners_intro.assign(synonyms = np.nan, antonyms = np.nan)\n",
    "common_words_after_preprocessing = award_winners_intro[\"common_words_after_preprocessing\"]\n",
    "\n",
    "def get_synonyms(common_words):\n",
    "    synonyms = [l.name() for word in common_words for syn in wordnet.synsets(word) for l in syn.lemmas() if l.name() != word]\n",
    "    return synonyms\n",
    "\n",
    "def get_antonyms(common_words):\n",
    "    antonyms = [l.antonyms()[0].name() for word in common_words for syn in wordnet.synsets(word) for l in syn.lemmas() if l.antonyms()]\n",
    "    return antonyms\n",
    "\n",
    "for i in range(len(common_words_after_preprocessing)):\n",
    "    synonyms, antonyms = get_synonyms(common_words_after_preprocessing[i]), get_antonyms(common_words_after_preprocessing[i])\n",
    "    award_winners_intro[\"synonyms\"][i] = list(OrderedDict.fromkeys(synonyms))\n",
    "    award_winners_intro[\"antonyms\"][i] = list(OrderedDict.fromkeys(antonyms))\n",
    "\n",
    "award_winners_intro.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334b9cbccb391e97a610fa1686459925ba3c38a6dfd8a581da5ac585bc22844f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
